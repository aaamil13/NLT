#!/usr/bin/env python3
"""
MCMC –∞–Ω–∞–ª–∏–∑ –∑–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—è –Ω–∞ No-Œõ –º–æ–¥–µ–ª–∞

–¢–æ–∑–∏ –º–æ–¥—É–ª –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è:
1. MCMC sampling —Å emcee
2. Priors –∑–∞ –∫–æ—Å–º–æ–ª–æ–≥–∏—á–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
3. Posterior –∞–Ω–∞–ª–∏–∑ –∏ –º–∞—Ä–≥–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
4. Corner plots –∑–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏ –∫–æ—Ä–µ–ª–∞—Ü–∏–∏
5. Convergence –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
6. –ü–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏ –Ω–µ—Å–∏–≥—É—Ä–Ω–æ—Å—Ç–∏
"""

import numpy as np
import matplotlib.pyplot as plt
import emcee
import corner
from scipy import stats
from scipy.optimize import minimize
from scipy.constants import c
from typing import Dict, List, Tuple, Optional, Callable
import logging
import warnings
from multiprocessing import Pool

# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–∞—à–∏—Ç–µ –º–æ–¥—É–ª–∏
from no_lambda_cosmology import NoLambdaCosmology
from observational_data import BAOObservationalData, CMBObservationalData, LikelihoodFunctions

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ —Å—Ç–∏–ª–æ–≤–µ—Ç–µ
try:
    plt.style.use('seaborn-v0_8')
except:
    try:
        plt.style.use('seaborn')
    except:
        pass  # –ò–∑–ø–æ–ª–∑–≤–∞–º–µ default —Å—Ç–∏–ª

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –ª–æ–≥–∏—Ä–∞–Ω–µ—Ç–æ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç—Ç–∞ –Ω–∞ —Å–≤–µ—Ç–ª–∏–Ω–∞—Ç–∞ –≤ km/s
c_km_s = 299792.458  # km/s


class MCMCAnalysis:
    """
    –ö–ª–∞—Å –∑–∞ MCMC –∞–Ω–∞–ª–∏–∑ –Ω–∞ No-Œõ –º–æ–¥–µ–ª–∞
    
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—è —Ñ—É–Ω–∫—Ü–∏–∏ –∑–∞:
    - –ü–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—è
    - –ë–∞–π–µ—Å–æ–≤ –∞–Ω–∞–ª–∏–∑
    - Posterior –º–∞—Ä–≥–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
    - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ —Ç–µ—Å—Ç–æ–≤–µ
    """
    
    def __init__(self, 
                 parameter_names: List[str] = None,
                 parameter_ranges: Dict[str, Tuple[float, float]] = None,
                 use_anisotropy: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ MCMC –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            parameter_names: –ò–º–µ–Ω–∞ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ –∑–∞ –∫–∞–ª–∏–±—Ä–∞—Ü–∏—è
            parameter_ranges: –î–∏–∞–ø–∞–∑–æ–Ω–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
            use_anisotropy: –î–∞–ª–∏ –¥–∞ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–∏—è
        """
        
        # –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª–Ω–∏ –¥–∞–Ω–Ω–∏
        self.bao_data = BAOObservationalData()
        self.cmb_data = CMBObservationalData()
        self.likelihood_func = LikelihoodFunctions(self.bao_data, self.cmb_data)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∞
        if parameter_names is None:
            parameter_names = ['H0', 'Omega_m', 'Omega_b', 'epsilon_bao', 'epsilon_cmb']
        
        self.parameter_names = parameter_names
        self.n_params = len(parameter_names)
        self.use_anisotropy = use_anisotropy
        
        # –î–∏–∞–ø–∞–∑–æ–Ω–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
        if parameter_ranges is None:
            parameter_ranges = {
                'H0': (60.0, 80.0),
                'Omega_m': (0.20, 0.50),
                'Omega_b': (0.030, 0.070),
                'epsilon_bao': (0.0, 0.10),
                'epsilon_cmb': (0.0, 0.08),
                'alpha': (0.5, 2.0),
                'beta': (0.0, 0.5),
                'gamma': (0.1, 1.0),
                'delta': (0.01, 0.20),
                'angular_strength': (0.1, 1.0)
            }
        
        self.parameter_ranges = parameter_ranges
        
        # MCMC –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.n_walkers = 50
        self.n_burn = 1000
        self.n_samples = 5000
        self.n_threads = 4
        
        # –†–µ–∑—É–ª—Ç–∞—Ç–∏
        self.sampler = None
        self.samples = None
        self.best_params = None
        self.param_uncertainties = None
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω MCMC –∞–Ω–∞–ª–∏–∑ —Å {self.n_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
        logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–∏: {self.parameter_names}")
    
    def log_prior(self, params: np.ndarray) -> float:
        """
        Logarithmic prior –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
        
        Args:
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∞
            
        Returns:
            Log-prior —Å—Ç–æ–π–Ω–æ—Å—Ç
        """
        log_prior_value = 0.0
        
        for i, param_name in enumerate(self.parameter_names):
            if param_name in self.parameter_ranges:
                param_min, param_max = self.parameter_ranges[param_name]
                
                if param_min <= params[i] <= param_max:
                    # Uniform prior
                    log_prior_value += -np.log(param_max - param_min)
                else:
                    return -np.inf
        
        return log_prior_value
    
    def log_likelihood(self, params: np.ndarray) -> float:
        """
        Logarithmic likelihood —Ñ—É–Ω–∫—Ü–∏—è
        
        Args:
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∞
            
        Returns:
            Log-likelihood —Å—Ç–æ–π–Ω–æ—Å—Ç
        """
        try:
            # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏ —Ä–µ—á–Ω–∏—Ü–∏
            param_dict = {}
            for i, param_name in enumerate(self.parameter_names):
                param_dict[param_name] = params[i]
            
            # –ó–∞–¥–∞–≤–∞–Ω–µ –Ω–∞ default —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –∑–∞ –ª–∏–ø—Å–≤–∞—â–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            default_params = {
                'H0': 67.4,
                'Omega_m': 0.315,
                'Omega_b': 0.049,
                'Omega_cdm': 0.266,
                'Omega_r': 8.24e-5,
                'epsilon_bao': 0.02,
                'epsilon_cmb': 0.015,
                'alpha': 1.2,
                'beta': 0.0,
                'gamma': 0.4,
                'delta': 0.08,
                'angular_strength': 0.6
            }
            
            # –û–±–Ω–æ–≤—è–≤–∞–Ω–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ –æ—Ç MCMC
            for key, value in param_dict.items():
                default_params[key] = value
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç
            if default_params['Omega_m'] < default_params['Omega_b']:
                return -np.inf
            
            # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª
            cosmo = NoLambdaCosmology(**default_params)
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∞
            model_predictions = self._calculate_model_predictions(cosmo)
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ likelihood
            log_like = self.likelihood_func.combined_likelihood(model_predictions)
            
            return log_like
            
        except Exception as e:
            logger.warning(f"–ì—Ä–µ—à–∫–∞ –≤ likelihood: {e}")
            return -np.inf
    
    def _calculate_model_predictions(self, cosmo: NoLambdaCosmology) -> Dict:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∞
        
        Args:
            cosmo: –ö–æ—Å–º–æ–ª–æ–≥–∏—á–µ–Ω –º–æ–¥–µ–ª
            
        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –º–æ–¥–µ–ª–∞
        """
        # –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ BAO –¥–∞–Ω–Ω–∏
        bao_combined = self.bao_data.get_combined_data()
        z_bao = bao_combined['redshifts']
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ D_V/r_s –∑–∞ BAO
        r_s = cosmo.sound_horizon_scale()
        DV_rs_model = []
        
        for z in z_bao:
            # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ D_V(z)
            D_A = cosmo.angular_diameter_distance(z)
            D_H = c_km_s / (cosmo.hubble_function(z) * 1000)  # Hubble distance
            D_V = (z * D_A**2 * D_H)**(1/3)  # Dilation distance
            
            DV_rs_model.append(D_V / r_s)
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ CMB –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        l_peaks_model = []
        for i in range(1, 4):  # –ü—ä—Ä–≤–∏ 3 –ø–∏–∫–∞
            theta_s = cosmo.cmb_angular_scale()
            l_peak = i * np.pi / theta_s
            l_peaks_model.append(l_peak)
        
        theta_s_model = cosmo.cmb_angular_scale()
        
        return {
            'DV_rs': np.array(DV_rs_model),
            'l_peaks': np.array(l_peaks_model),
            'theta_s': theta_s_model
        }
    
    def log_posterior(self, params: np.ndarray) -> float:
        """
        Logarithmic posterior –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç
        
        Args:
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∞
            
        Returns:
            Log-posterior —Å—Ç–æ–π–Ω–æ—Å—Ç
        """
        log_prior_val = self.log_prior(params)
        if not np.isfinite(log_prior_val):
            return -np.inf
        
        log_like_val = self.log_likelihood(params)
        if not np.isfinite(log_like_val):
            return -np.inf
        
        return log_prior_val + log_like_val
    
    def find_best_fit(self, initial_guess: np.ndarray = None) -> Tuple[np.ndarray, float]:
        """
        –ù–∞–º–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–∞–π-–¥–æ–±—Ä–∏—è fit —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        
        Args:
            initial_guess: –ù–∞—á–∞–ª–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
            
        Returns:
            –ù–∞–π-–¥–æ–±—Ä–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∏ negative log-likelihood
        """
        if initial_guess is None:
            # –í–∑–∏–º–∞–º–µ —Å—Ä–µ–¥–Ω–∏—Ç–µ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –æ—Ç ranges
            initial_guess = []
            for param_name in self.parameter_names:
                param_min, param_max = self.parameter_ranges[param_name]
                initial_guess.append((param_min + param_max) / 2)
            initial_guess = np.array(initial_guess)
        
        def negative_log_posterior(params):
            return -self.log_posterior(params)
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        result = minimize(negative_log_posterior, initial_guess, method='L-BFGS-B')
        
        if result.success:
            logger.info(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ —É—Å–ø–µ—à–Ω–∞: {result.fun:.3f}")
            self.best_params = result.x
            return result.x, result.fun
        else:
            logger.warning(f"–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–µ—É—Å–ø–µ—à–Ω–∞: {result.message}")
            return initial_guess, negative_log_posterior(initial_guess)
    
    def run_mcmc(self, 
                 n_walkers: int = None,
                 n_burn: int = None,
                 n_samples: int = None,
                 initial_params: np.ndarray = None,
                 progress: bool = True) -> None:
        """
        –ò–∑–ø—ä–ª–Ω–µ–Ω–∏–µ –Ω–∞ MCMC sampling
        
        Args:
            n_walkers: –ë—Ä–æ–π walkers
            n_burn: –ë—Ä–æ–π burn-in —Å—Ç—ä–ø–∫–∏
            n_samples: –ë—Ä–æ–π samples
            initial_params: –ù–∞—á–∞–ª–Ω–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏
            progress: –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å–∞
        """
        
        # –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ default —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        if n_walkers is None:
            n_walkers = self.n_walkers
        if n_burn is None:
            n_burn = self.n_burn
        if n_samples is None:
            n_samples = self.n_samples
        
        # –ù–∞–º–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–∞–π-–¥–æ–±—Ä–∏—è fit –∑–∞ –Ω–∞—á–∞–ª–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        if initial_params is None:
            logger.info("–¢—ä—Ä—Å–µ–Ω–µ –Ω–∞ –Ω–∞–π-–¥–æ–±—Ä–∏—è fit...")
            initial_params, _ = self.find_best_fit()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω–µ –Ω–∞ walkers –æ–∫–æ–ª–æ –Ω–∞–π-–¥–æ–±—Ä–∏—è fit
        pos = initial_params + 1e-4 * np.random.randn(n_walkers, self.n_params)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ priors
        for i in range(n_walkers):
            while not np.isfinite(self.log_prior(pos[i])):
                pos[i] = initial_params + 1e-4 * np.random.randn(self.n_params)
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ sampler
        logger.info(f"–°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ MCMC: {n_walkers} walkers, {n_burn} burn-in, {n_samples} samples")
        
        self.sampler = emcee.EnsembleSampler(
            n_walkers, 
            self.n_params, 
            self.log_posterior
        )
        
        # Burn-in
        logger.info("–ò–∑–ø—ä–ª–Ω–µ–Ω–∏–µ –Ω–∞ burn-in...")
        pos, _, _ = self.sampler.run_mcmc(pos, n_burn, progress=progress)
        self.sampler.reset()
        
        # Production run
        logger.info("–ò–∑–ø—ä–ª–Ω–µ–Ω–∏–µ –Ω–∞ production sampling...")
        self.sampler.run_mcmc(pos, n_samples, progress=progress)
        
        # –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ samples
        self.samples = self.sampler.get_chain(discard=0, thin=1, flat=True)
        
        logger.info(f"MCMC –∑–∞–≤—ä—Ä—à–µ–Ω: {self.samples.shape[0]} samples")
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        self._analyze_results()
    
    def _analyze_results(self) -> None:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞ MCMC —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
        
        if self.samples is None:
            logger.warning("–ù—è–º–∞ samples –∑–∞ –∞–Ω–∞–ª–∏–∑")
            return
        
        # –°—Ä–µ–¥–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –∏ –Ω–µ—Å–∏–≥—É—Ä–Ω–æ—Å—Ç–∏
        self.param_uncertainties = {}
        
        for i, param_name in enumerate(self.parameter_names):
            samples_param = self.samples[:, i]
            
            # –°—Ä–µ–¥–Ω–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç
            mean_val = np.mean(samples_param)
            
            # –ù–µ—Å–∏–≥—É—Ä–Ω–æ—Å—Ç–∏ (68% credible interval)
            percentiles = np.percentile(samples_param, [16, 50, 84])
            lower_err = percentiles[1] - percentiles[0]
            upper_err = percentiles[2] - percentiles[1]
            
            self.param_uncertainties[param_name] = {
                'mean': mean_val,
                'median': percentiles[1],
                'lower_err': lower_err,
                'upper_err': upper_err,
                'std': np.std(samples_param)
            }
        
        # –ê–≤—Ç–æ–∫–æ—Ä–µ–ª–∞—Ü–∏–æ–Ω–µ–Ω –∞–Ω–∞–ª–∏–∑
        try:
            autocorr_times = self.sampler.get_autocorr_time()
            logger.info(f"–ê–≤—Ç–æ–∫–æ—Ä–µ–ª–∞—Ü–∏–æ–Ω–Ω–∏ –≤—Ä–µ–º–µ–Ω–∞: {autocorr_times}")
        except Exception as e:
            logger.warning(f"–ù–µ –º–æ–∂–µ –¥–∞ —Å–µ –∏–∑—á–∏—Å–ª–∏ –∞–≤—Ç–æ–∫–æ—Ä–µ–ª–∞—Ü–∏–æ–Ω–Ω–æ—Ç–æ –≤—Ä–µ–º–µ: {e}")
        
        # Acceptance fraction
        acceptance_fraction = np.mean(self.sampler.acceptance_fraction)
        logger.info(f"Acceptance fraction: {acceptance_fraction:.3f}")
    
    def plot_chains(self, save_path: str = None) -> None:
        """
        –ì—Ä–∞—Ñ–∏–∫–∏ –Ω–∞ MCMC chains
        
        Args:
            save_path: –ü—ä—Ç –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ
        """
        if self.sampler is None:
            logger.warning("–ù—è–º–∞ sampler –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
            return
        
        fig, axes = plt.subplots(self.n_params, 1, figsize=(12, 2*self.n_params))
        
        if self.n_params == 1:
            axes = [axes]
        
        samples = self.sampler.get_chain()
        
        for i, param_name in enumerate(self.parameter_names):
            ax = axes[i]
            ax.plot(samples[:, :, i], alpha=0.3)
            ax.set_ylabel(param_name)
            ax.grid(True, alpha=0.3)
        
        axes[-1].set_xlabel('–°—Ç—ä–ø–∫–∞')
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def plot_corner(self, save_path: str = None, truth_values: Dict = None) -> None:
        """
        Corner plot –∑–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏—Ç–µ –∫–æ—Ä–µ–ª–∞—Ü–∏–∏
        
        Args:
            save_path: –ü—ä—Ç –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ
            truth_values: –ò—Å—Ç–∏–Ω—Å–∫–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
        """
        if self.samples is None:
            logger.warning("–ù—è–º–∞ samples –∑–∞ corner plot")
            return
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ truth values
        truths = None
        if truth_values:
            truths = []
            for param_name in self.parameter_names:
                if param_name in truth_values:
                    truths.append(truth_values[param_name])
                else:
                    truths.append(None)
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ corner plot
        fig = corner.corner(
            self.samples,
            labels=self.parameter_names,
            truths=truths,
            quantiles=[0.16, 0.5, 0.84],
            show_titles=True,
            title_kwargs={"fontsize": 12}
        )
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def calculate_evidence(self) -> Dict:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ Bayesian evidence (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ)
        
        Returns:
            –†–µ—á–Ω–∏–∫ —Å evidence –æ—Ü–µ–Ω–∫–∏
        """
        if self.samples is None:
            logger.warning("–ù—è–º–∞ samples –∑–∞ evidence –∏–∑—á–∏—Å–ª–µ–Ω–∏–µ")
            return {}
        
        # Harmonic mean estimator (–ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ)
        log_likelihoods = []
        for i in range(len(self.samples)):
            log_like = self.log_likelihood(self.samples[i])
            if np.isfinite(log_like):
                log_likelihoods.append(log_like)
        
        if not log_likelihoods:
            return {}
        
        log_likelihoods = np.array(log_likelihoods)
        
        # Harmonic mean
        max_log_like = np.max(log_likelihoods)
        shifted_log_likes = log_likelihoods - max_log_like
        
        harmonic_mean = -np.log(np.mean(np.exp(-shifted_log_likes))) + max_log_like
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏
        n_data = len(self.bao_data.get_combined_data()['redshifts']) + 4  # BAO + CMB
        
        # –ù–∞–π-–¥–æ–±—ä—Ä likelihood
        best_log_like = np.max(log_likelihoods)
        
        # AIC –∏ BIC
        aic = 2 * self.n_params - 2 * best_log_like
        bic = np.log(n_data) * self.n_params - 2 * best_log_like
        
        return {
            'log_evidence_harmonic': harmonic_mean,
            'best_log_likelihood': best_log_like,
            'aic': aic,
            'bic': bic,
            'n_parameters': self.n_params,
            'n_data': n_data
        }
    
    def summary(self) -> None:
        """–†–µ–∑—é–º–µ –Ω–∞ MCMC –∞–Ω–∞–ª–∏–∑–∞"""
        
        print("üìä MCMC –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¢–ê–¢–ò")
        print("=" * 70)
        
        if self.param_uncertainties is None:
            print("–ù—è–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏")
            return
        
        print(f"\nüîç –ü–ê–†–ê–ú–ï–¢–†–ò–ß–ù–ò –û–¶–ï–ù–ö–ò:")
        print(f"{'–ü–∞—Ä–∞–º–µ—Ç—ä—Ä':<15} {'–°—Ä–µ–¥–Ω–∞':<10} {'–ú–µ–¥–∏–∞–Ω–∞':<10} {'¬±–î–æ–ª–Ω–∞':<10} {'¬±–ì–æ—Ä–Ω–∞':<10}")
        print("-" * 70)
        
        for param_name in self.parameter_names:
            if param_name in self.param_uncertainties:
                stats = self.param_uncertainties[param_name]
                print(f"{param_name:<15} {stats['mean']:<10.4f} {stats['median']:<10.4f} "
                      f"{stats['lower_err']:<10.4f} {stats['upper_err']:<10.4f}")
        
        # Evidence –∞–Ω–∞–ª–∏–∑
        evidence = self.calculate_evidence()
        if evidence:
            print(f"\nüìà –ë–ê–ô–ï–°–û–í –ê–ù–ê–õ–ò–ó:")
            print(f"  Log-evidence (harmonic): {evidence['log_evidence_harmonic']:.2f}")
            print(f"  Best log-likelihood: {evidence['best_log_likelihood']:.2f}")
            print(f"  AIC: {evidence['aic']:.2f}")
            print(f"  BIC: {evidence['bic']:.2f}")
        
        # –ê–≤—Ç–æ–∫–æ—Ä–µ–ª–∞—Ü–∏—è
        if self.sampler:
            try:
                autocorr_times = self.sampler.get_autocorr_time()
                print(f"\n‚è±Ô∏è  –ê–í–¢–û–ö–û–†–ï–õ–ê–¶–ò–û–ù–ù–ò –í–†–ï–ú–ï–ù–ê:")
                for i, param_name in enumerate(self.parameter_names):
                    print(f"  {param_name}: {autocorr_times[i]:.1f}")
            except:
                pass
            
            acceptance = np.mean(self.sampler.acceptance_fraction)
            print(f"\n‚úÖ ACCEPTANCE FRACTION: {acceptance:.3f}")


def test_mcmc_analysis():
    """–¢–µ—Å—Ç –Ω–∞ MCMC –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("üß™ –¢–ï–°–¢ –ù–ê MCMC –ê–ù–ê–õ–ò–ó")
    print("=" * 70)
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ MCMC –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    mcmc = MCMCAnalysis(
        parameter_names=['H0', 'Omega_m', 'epsilon_bao'],
        use_anisotropy=True
    )
    
    # –ö—Ä–∞—Ç—ä–∫ —Ç–µ—Å—Ç run
    mcmc.n_walkers = 20
    mcmc.n_burn = 50
    mcmc.n_samples = 200
    
    print("–°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤ MCMC...")
    mcmc.run_mcmc(progress=True)
    
    # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
    mcmc.summary()
    
    # –ì—Ä–∞—Ñ–∏–∫–∏
    mcmc.plot_chains(save_path='mcmc_chains_test.png')
    mcmc.plot_corner(save_path='mcmc_corner_test.png')
    
    print("\n‚úÖ MCMC —Ç–µ—Å—Ç—ä—Ç –∑–∞–≤—ä—Ä—à–∏ —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    test_mcmc_analysis() 