#!/usr/bin/env python3
"""
Nested Sampling –∞–Ω–∞–ª–∏–∑ –∑–∞ –º–æ–¥–µ–ª —Å–µ–ª–µ–∫—Ü–∏—è –∏ Bayesian evidence

–¢–æ–∑–∏ –º–æ–¥—É–ª –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—è:
1. Nested sampling —Å dynesty
2. –ú–æ–¥–µ–ª —Å–µ–ª–µ–∫—Ü–∏—è ŒõCDM vs No-Œõ
3. Bayesian evidence –∏–∑—á–∏—Å–ª–µ–Ω–∏–µ
4. Information criteria (AIC, BIC, DIC)
5. Posterior probability –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è
6. Model comparison –∏ odds ratios
"""

import numpy as np
import matplotlib.pyplot as plt
from dynesty import DynamicNestedSampler, NestedSampler
from dynesty.plotting import runplot, traceplot, cornerplot
from dynesty.utils import resample_equal
import corner
from scipy import stats
from typing import Dict, List, Tuple, Optional, Callable
import logging
import warnings
import time
from multiprocessing import Pool

# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–∞—à–∏—Ç–µ –º–æ–¥—É–ª–∏
from mcmc_analysis import MCMCAnalysis
from observational_data import BAOObservationalData, CMBObservationalData, LikelihoodFunctions
from no_lambda_cosmology import NoLambdaCosmology

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –ª–æ–≥–∏—Ä–∞–Ω–µ—Ç–æ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NestedSamplingAnalysis:
    """
    –ö–ª–∞—Å –∑–∞ nested sampling –∞–Ω–∞–ª–∏–∑ –Ω–∞ –∫–æ—Å–º–æ–ª–æ–≥–∏—á–Ω–∏ –º–æ–¥–µ–ª–∏
    
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤—è —Ñ—É–Ω–∫—Ü–∏–∏ –∑–∞:
    - Bayesian evidence –∏–∑—á–∏—Å–ª–µ–Ω–∏–µ
    - –ú–æ–¥–µ–ª —Å–µ–ª–µ–∫—Ü–∏—è
    - Information criteria
    - Model comparison
    """
    
    def __init__(self, 
                 parameter_names: List[str] = None,
                 parameter_ranges: Dict[str, Tuple[float, float]] = None,
                 nlive: int = 1000):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ nested sampling –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            parameter_names: –ò–º–µ–Ω–∞ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
            parameter_ranges: –î–∏–∞–ø–∞–∑–æ–Ω–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
            nlive: –ë—Ä–æ–π –∂–∏–≤–∏ —Ç–æ—á–∫–∏ –∑–∞ nested sampling
        """
        
        # –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –Ω–∞–±–ª—é–¥–∞—Ç–µ–ª–Ω–∏ –¥–∞–Ω–Ω–∏
        self.bao_data = BAOObservationalData()
        self.cmb_data = CMBObservationalData()
        self.likelihood_func = LikelihoodFunctions(self.bao_data, self.cmb_data)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∞
        if parameter_names is None:
            parameter_names = ['H0', 'Omega_m', 'Omega_b', 'epsilon_bao', 'epsilon_cmb']
        
        self.parameter_names = parameter_names
        self.n_params = len(parameter_names)
        
        # –î–∏–∞–ø–∞–∑–æ–Ω–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
        if parameter_ranges is None:
            parameter_ranges = {
                'H0': (60.0, 80.0),
                'Omega_m': (0.20, 0.50),
                'Omega_b': (0.030, 0.070),
                'epsilon_bao': (0.0, 0.10),
                'epsilon_cmb': (0.0, 0.08),
                'alpha': (0.5, 2.0),
                'beta': (0.0, 0.5),
                'gamma': (0.1, 1.0),
                'delta': (0.01, 0.20),
                'angular_strength': (0.1, 1.0)
            }
        
        self.parameter_ranges = parameter_ranges
        
        # Nested sampling –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
        self.nlive = nlive
        self.dlogz = 0.01
        self.maxiter = 10000
        self.maxcall = 1000000
        
        # –†–µ–∑—É–ª—Ç–∞—Ç–∏
        self.sampler = None
        self.results = None
        self.log_evidence = None
        self.log_evidence_err = None
        self.posterior_samples = None
        
        logger.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω nested sampling –∞–Ω–∞–ª–∏–∑ —Å {self.n_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
        logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–∏: {self.parameter_names}")
        logger.info(f"Nlive: {self.nlive}")
    
    def ptform(self, u: np.ndarray) -> np.ndarray:
        """
        Prior transform —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ nested sampling
        
        Args:
            u: Uniform random values [0,1]
            
        Returns:
            Transformed parameters
        """
        x = np.zeros(self.n_params)
        
        for i, param_name in enumerate(self.parameter_names):
            if param_name in self.parameter_ranges:
                param_min, param_max = self.parameter_ranges[param_name]
                x[i] = param_min + u[i] * (param_max - param_min)
            else:
                x[i] = u[i]  # Default [0,1] range
        
        return x
    
    def loglike(self, params: np.ndarray) -> float:
        """
        Log-likelihood —Ñ—É–Ω–∫—Ü–∏—è –∑–∞ nested sampling
        
        Args:
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –Ω–∞ –º–æ–¥–µ–ª–∞
            
        Returns:
            Log-likelihood —Å—Ç–æ–π–Ω–æ—Å—Ç
        """
        try:
            # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏ —Ä–µ—á–Ω–∏—Ü–∏
            param_dict = {}
            for i, param_name in enumerate(self.parameter_names):
                param_dict[param_name] = params[i]
            
            # –ó–∞–¥–∞–≤–∞–Ω–µ –Ω–∞ default —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
            default_params = {
                'H0': 67.4,
                'Omega_m': 0.315,
                'Omega_b': 0.049,
                'Omega_cdm': 0.266,
                'Omega_r': 8.24e-5,
                'epsilon_bao': 0.02,
                'epsilon_cmb': 0.015,
                'alpha': 1.2,
                'beta': 0.0,
                'gamma': 0.4,
                'delta': 0.08,
                'angular_strength': 0.6
            }
            
            # –û–±–Ω–æ–≤—è–≤–∞–Ω–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
            for key, value in param_dict.items():
                default_params[key] = value
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç
            if default_params['Omega_m'] < default_params['Omega_b']:
                return -np.inf
            
            # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–æ–¥–µ–ª
            cosmo = NoLambdaCosmology(**default_params)
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ç–∞
            model_predictions = self._calculate_model_predictions(cosmo)
            
            # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ likelihood
            log_like = self.likelihood_func.combined_likelihood(model_predictions)
            
            return log_like
            
        except Exception as e:
            logger.debug(f"–ì—Ä–µ—à–∫–∞ –≤ likelihood: {e}")
            return -np.inf
    
    def _calculate_model_predictions(self, cosmo: NoLambdaCosmology) -> Dict:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ç–∞ –Ω–∞ –º–æ–¥–µ–ª–∞
        
        Args:
            cosmo: –ö–æ—Å–º–æ–ª–æ–≥–∏—á–µ–Ω –º–æ–¥–µ–ª
            
        Returns:
            –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –º–æ–¥–µ–ª–∞
        """
        # –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ BAO –¥–∞–Ω–Ω–∏
        bao_combined = self.bao_data.get_combined_data()
        z_bao = bao_combined['redshifts']
        
        # –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç—Ç–∞ –Ω–∞ —Å–≤–µ—Ç–ª–∏–Ω–∞—Ç–∞
        c_km_s = 299792.458  # km/s
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ D_V/r_s –∑–∞ BAO
        r_s = cosmo.sound_horizon_scale()
        DV_rs_model = []
        
        for z in z_bao:
            # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ D_V(z)
            D_A = cosmo.angular_diameter_distance(z)
            D_H = c_km_s / (cosmo.hubble_function(z) * 1000)  # Hubble distance
            D_V = (z * D_A**2 * D_H)**(1/3)  # Dilation distance
            
            DV_rs_model.append(D_V / r_s)
        
        # –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ CMB –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        l_peaks_model = []
        for i in range(1, 4):  # –ü—ä—Ä–≤–∏ 3 –ø–∏–∫–∞
            theta_s = cosmo.cmb_angular_scale()
            l_peak = i * np.pi / theta_s
            l_peaks_model.append(l_peak)
        
        theta_s_model = cosmo.cmb_angular_scale()
        
        return {
            'DV_rs': np.array(DV_rs_model),
            'l_peaks': np.array(l_peaks_model),
            'theta_s': theta_s_model
        }
    
    def run_nested_sampling(self, 
                          nlive: int = None,
                          dlogz: float = None,
                          dynamic: bool = True,
                          progress: bool = True) -> None:
        """
        –ò–∑–ø—ä–ª–Ω–µ–Ω–∏–µ –Ω–∞ nested sampling
        
        Args:
            nlive: –ë—Ä–æ–π –∂–∏–≤–∏ —Ç–æ—á–∫–∏
            dlogz: Accuracy –≤ log-evidence
            dynamic: –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ dynamic nested sampling
            progress: –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ –ø—Ä–æ–≥—Ä–µ—Å
        """
        
        # –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ default —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        if nlive is None:
            nlive = self.nlive
        if dlogz is None:
            dlogz = self.dlogz
        
        logger.info(f"–°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ nested sampling:")
        logger.info(f"  Nlive: {nlive}")
        logger.info(f"  dlogz: {dlogz}")
        logger.info(f"  Dynamic: {dynamic}")
        
        start_time = time.time()
        
        # –ò–∑–±–æ—Ä –Ω–∞ sampler
        if dynamic:
            sampler = DynamicNestedSampler(
                self.loglike,
                self.ptform,
                self.n_params,
                nlive=nlive
            )
        else:
            sampler = NestedSampler(
                self.loglike,
                self.ptform,
                self.n_params,
                nlive=nlive
            )
        
        # –ò–∑–ø—ä–ª–Ω–µ–Ω–∏–µ –Ω–∞ sampling
        logger.info("–ò–∑–ø—ä–ª–Ω–µ–Ω–∏–µ –Ω–∞ nested sampling...")
        
        if dynamic:
            sampler.run_nested(print_progress=progress)
        else:
            sampler.run_nested(print_progress=progress)
        
        # –°—ä—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        self.sampler = sampler
        self.results = sampler.results
        
        # –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ evidence
        self.log_evidence = self.results.logz[-1]
        self.log_evidence_err = self.results.logzerr[-1]
        
        # Posterior samples
        self.posterior_samples = resample_equal(
            self.results.samples,
            self.results.logwt
        )
        
        end_time = time.time()
        runtime = end_time - start_time
        
        logger.info(f"Nested sampling –∑–∞–≤—ä—Ä—à–µ–Ω –∑–∞ {runtime:.1f} —Å–µ–∫—É–Ω–¥–∏")
        logger.info(f"Log-evidence: {self.log_evidence:.3f} ¬± {self.log_evidence_err:.3f}")
        logger.info(f"Posterior samples: {len(self.posterior_samples)}")
        
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        self._analyze_results()
    
    def _analyze_results(self) -> None:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞ nested sampling —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
        
        if self.results is None:
            logger.warning("–ù—è–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ –∞–Ω–∞–ª–∏–∑")
            return
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∏ –∫—Ä–∏—Ç–µ—Ä–∏–∏
        n_data = len(self.bao_data.get_combined_data()['redshifts']) + 4  # BAO + CMB
        
        # –ù–∞–π-–¥–æ–±—ä—Ä likelihood
        best_log_like = np.max(self.results.logl)
        
        # AIC –∏ BIC
        aic = 2 * self.n_params - 2 * best_log_like
        bic = np.log(n_data) * self.n_params - 2 * best_log_like
        
        # DIC (Deviance Information Criterion)
        posterior_mean_loglike = np.mean(self.results.logl)
        effective_params = 2 * (best_log_like - posterior_mean_loglike)
        dic = -2 * posterior_mean_loglike + 2 * effective_params
        
        # –°—ä—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è—Ç–∞
        self.info_criteria = {
            'log_evidence': self.log_evidence,
            'log_evidence_err': self.log_evidence_err,
            'best_log_likelihood': best_log_like,
            'aic': aic,
            'bic': bic,
            'dic': dic,
            'effective_params': effective_params,
            'n_parameters': self.n_params,
            'n_data': n_data
        }
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.param_stats = {}
        
        for i, param_name in enumerate(self.parameter_names):
            samples_param = self.posterior_samples[:, i]
            
            # –°—Ä–µ–¥–Ω–∞ —Å—Ç–æ–π–Ω–æ—Å—Ç
            mean_val = np.mean(samples_param)
            
            # –ù–µ—Å–∏–≥—É—Ä–Ω–æ—Å—Ç–∏ (68% credible interval)
            percentiles = np.percentile(samples_param, [16, 50, 84])
            lower_err = percentiles[1] - percentiles[0]
            upper_err = percentiles[2] - percentiles[1]
            
            self.param_stats[param_name] = {
                'mean': mean_val,
                'median': percentiles[1],
                'lower_err': lower_err,
                'upper_err': upper_err,
                'std': np.std(samples_param)
            }
        
        logger.info("–ê–Ω–∞–ª–∏–∑ –Ω–∞ nested sampling —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ –∑–∞–≤—ä—Ä—à–µ–Ω")
    
    def plot_run(self, save_path: str = None) -> None:
        """
        –ì—Ä–∞—Ñ–∏–∫–∏ –Ω–∞ nested sampling run
        
        Args:
            save_path: –ü—ä—Ç –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ
        """
        if self.results is None:
            logger.warning("–ù—è–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
            return
        
        fig, axes = runplot(self.results, color='blue')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def plot_trace(self, save_path: str = None) -> None:
        """
        Trace plots –∑–∞ nested sampling
        
        Args:
            save_path: –ü—ä—Ç –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ
        """
        if self.results is None:
            logger.warning("–ù—è–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è")
            return
        
        fig, axes = traceplot(self.results, labels=self.parameter_names)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def plot_corner(self, save_path: str = None, truth_values: Dict = None) -> None:
        """
        Corner plot –∑–∞ nested sampling —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
        
        Args:
            save_path: –ü—ä—Ç –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ
            truth_values: –ò—Å—Ç–∏–Ω—Å–∫–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        """
        if self.posterior_samples is None:
            logger.warning("–ù—è–º–∞ posterior samples –∑–∞ corner plot")
            return
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–∞ truth values
        truths = None
        if truth_values:
            truths = []
            for param_name in self.parameter_names:
                if param_name in truth_values:
                    truths.append(truth_values[param_name])
                else:
                    truths.append(None)
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ corner plot
        fig = corner.corner(
            self.posterior_samples,
            labels=self.parameter_names,
            truths=truths,
            quantiles=[0.16, 0.5, 0.84],
            show_titles=True,
            title_kwargs={"fontsize": 12}
        )
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        plt.show()
    
    def calculate_bayes_factor(self, other_model: 'NestedSamplingAnalysis') -> Dict:
        """
        –ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ Bayes factor –º–µ–∂–¥—É –¥–≤–∞ –º–æ–¥–µ–ª–∞
        
        Args:
            other_model: –î—Ä—É–≥ –º–æ–¥–µ–ª –∑–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
            
        Returns:
            Bayes factor –∞–Ω–∞–ª–∏–∑
        """
        if self.log_evidence is None or other_model.log_evidence is None:
            logger.warning("–ï–¥–Ω–æ –∏–ª–∏ –¥–≤–µ—Ç–µ –º–æ–¥–µ–ª–∏ –Ω—è–º–∞ evidence")
            return {}
        
        # Bayes factor
        log_bayes_factor = self.log_evidence - other_model.log_evidence
        bayes_factor = np.exp(log_bayes_factor)
        
        # –ù–µ—Å–∏–≥—É—Ä–Ω–æ—Å—Ç –≤ Bayes factor
        log_bf_err = np.sqrt(self.log_evidence_err**2 + other_model.log_evidence_err**2)
        
        # Jeffreys' scale –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
        if np.abs(log_bayes_factor) < 1.0:
            interpretation = "Inconclusive"
        elif np.abs(log_bayes_factor) < 2.5:
            interpretation = "Weak evidence"
        elif np.abs(log_bayes_factor) < 5.0:
            interpretation = "Moderate evidence"
        else:
            interpretation = "Strong evidence"
        
        preferred_model = "Model 1 (this)" if log_bayes_factor > 0 else "Model 2 (other)"
        
        return {
            'log_bayes_factor': log_bayes_factor,
            'log_bayes_factor_err': log_bf_err,
            'bayes_factor': bayes_factor,
            'preferred_model': preferred_model,
            'interpretation': interpretation,
            'model1_log_evidence': self.log_evidence,
            'model2_log_evidence': other_model.log_evidence
        }
    
    def summary(self) -> None:
        """–†–µ–∑—é–º–µ –Ω–∞ nested sampling –∞–Ω–∞–ª–∏–∑–∞"""
        
        print("üéØ NESTED SAMPLING –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¢–ê–¢–ò")
        print("=" * 70)
        
        if self.results is None:
            print("–ù—è–º–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä–∞–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏")
            return
        
        # Evidence –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"\nüìä BAYESIAN EVIDENCE:")
        print(f"  Log-evidence: {self.log_evidence:.3f} ¬± {self.log_evidence_err:.3f}")
        print(f"  Evidence: {np.exp(self.log_evidence):.2e}")
        
        # Information criteria
        if hasattr(self, 'info_criteria'):
            info = self.info_criteria
            print(f"\nüìà INFORMATION CRITERIA:")
            print(f"  AIC: {info['aic']:.2f}")
            print(f"  BIC: {info['bic']:.2f}")
            print(f"  DIC: {info['dic']:.2f}")
            print(f"  Effective parameters: {info['effective_params']:.1f}")
            print(f"  Best log-likelihood: {info['best_log_likelihood']:.2f}")
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏—á–Ω–∏ –æ—Ü–µ–Ω–∫–∏
        if hasattr(self, 'param_stats'):
            print(f"\nüîç –ü–ê–†–ê–ú–ï–¢–†–ò–ß–ù–ò –û–¶–ï–ù–ö–ò:")
            print(f"{'–ü–∞—Ä–∞–º–µ—Ç—ä—Ä':<15} {'–°—Ä–µ–¥–Ω–∞':<10} {'–ú–µ–¥–∏–∞–Ω–∞':<10} {'¬±–î–æ–ª–Ω–∞':<10} {'¬±–ì–æ—Ä–Ω–∞':<10}")
            print("-" * 70)
            
            for param_name in self.parameter_names:
                if param_name in self.param_stats:
                    stats = self.param_stats[param_name]
                    print(f"{param_name:<15} {stats['mean']:<10.4f} {stats['median']:<10.4f} "
                          f"{stats['lower_err']:<10.4f} {stats['upper_err']:<10.4f}")
        
        # Sampling –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"\n‚öôÔ∏è  SAMPLING INFORMATION:")
        print(f"  Nlive: {self.nlive}")
        print(f"  Samples: {len(self.posterior_samples) if self.posterior_samples is not None else 'N/A'}")
        print(f"  Iterations: {len(self.results.logz)}")
        print(f"  Calls: {self.results.ncall}")


def compare_models(model1: NestedSamplingAnalysis, 
                  model2: NestedSamplingAnalysis,
                  model1_name: str = "Model 1",
                  model2_name: str = "Model 2") -> None:
    """
    –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É –¥–≤–∞ –º–æ–¥–µ–ª–∞
    
    Args:
        model1: –ü—ä—Ä–≤–∏ –º–æ–¥–µ–ª
        model2: –í—Ç–æ—Ä–∏ –º–æ–¥–µ–ª
        model1_name: –ò–º–µ –Ω–∞ –ø—ä—Ä–≤–∏—è –º–æ–¥–µ–ª
        model2_name: –ò–º–µ –Ω–∞ –≤—Ç–æ—Ä–∏—è –º–æ–¥–µ–ª
    """
    
    print("üîÑ –ú–û–î–ï–õ –°–†–ê–í–ù–ï–ù–ò–ï")
    print("=" * 70)
    
    # Bayes factor –∞–Ω–∞–ª–∏–∑
    bf_analysis = model1.calculate_bayes_factor(model2)
    
    if bf_analysis:
        print(f"\nüìä BAYES FACTOR –ê–ù–ê–õ–ò–ó:")
        print(f"  {model1_name} vs {model2_name}")
        print(f"  Log Bayes Factor: {bf_analysis['log_bayes_factor']:.3f} ¬± {bf_analysis['log_bayes_factor_err']:.3f}")
        print(f"  Bayes Factor: {bf_analysis['bayes_factor']:.2e}")
        print(f"  –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–Ω –º–æ–¥–µ–ª: {bf_analysis['preferred_model']}")
        print(f"  –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è: {bf_analysis['interpretation']}")
        
        print(f"\nüìà EVIDENCE COMPARISON:")
        print(f"  {model1_name} log-evidence: {bf_analysis['model1_log_evidence']:.3f}")
        print(f"  {model2_name} log-evidence: {bf_analysis['model2_log_evidence']:.3f}")
    
    # Information criteria —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    if hasattr(model1, 'info_criteria') and hasattr(model2, 'info_criteria'):
        print(f"\nüìä INFORMATION CRITERIA COMPARISON:")
        print(f"{'Criterion':<15} {model1_name:<15} {model2_name:<15} {'Difference':<15}")
        print("-" * 70)
        
        for criterion in ['aic', 'bic', 'dic']:
            val1 = model1.info_criteria[criterion]
            val2 = model2.info_criteria[criterion]
            diff = val1 - val2
            print(f"{criterion.upper():<15} {val1:<15.2f} {val2:<15.2f} {diff:<15.2f}")


def test_nested_sampling():
    """–¢–µ—Å—Ç –Ω–∞ nested sampling –∞–Ω–∞–ª–∏–∑–∞"""
    
    print("üß™ –¢–ï–°–¢ –ù–ê NESTED SAMPLING –ê–ù–ê–õ–ò–ó")
    print("=" * 70)
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ nested sampling –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    ns = NestedSamplingAnalysis(
        parameter_names=['H0', 'Omega_m', 'epsilon_bao'],
        nlive=100  # –ú–∞–ª–∫–æ –∑–∞ —Ç–µ—Å—Ç
    )
    
    print("–°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤ nested sampling...")
    ns.run_nested_sampling(nlive=100, dlogz=0.1, progress=True)
    
    # –ü–æ–∫–∞–∑–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
    ns.summary()
    
    # –ì—Ä–∞—Ñ–∏–∫–∏
    ns.plot_run(save_path='nested_sampling_run_test.png')
    ns.plot_trace(save_path='nested_sampling_trace_test.png')
    ns.plot_corner(save_path='nested_sampling_corner_test.png')
    
    print("\n‚úÖ Nested sampling —Ç–µ—Å—Ç—ä—Ç –∑–∞–≤—ä—Ä—à–∏ —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    test_nested_sampling() 