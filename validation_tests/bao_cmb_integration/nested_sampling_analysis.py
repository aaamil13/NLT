#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω Nested Sampling –∞–Ω–∞–ª–∏–∑ –∑–∞ –º–æ–¥–µ–ª —Å–µ–ª–µ–∫—Ü–∏—è

–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
1. –ú–∏–Ω–∏–º–∞–ª–µ–Ω –∫–æ–Ω—Å–æ–ª–µ–Ω –∏–∑—Ö–æ–¥
2. –ö–µ—à–∏—Ä–∞–Ω–µ –Ω–∞ –∏–∑—á–∏—Å–ª–µ–Ω–∏—è
3. –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–∞–Ω–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏
4. –ü–æ-–µ—Ñ–∏–∫–∞—Å–Ω–∏ likelihood —Ñ—É–Ω–∫—Ü–∏–∏
5. Numba –∫–æ–º–ø–∏–ª–∞—Ü–∏—è –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç
"""

import numpy as np
import matplotlib.pyplot as plt
from dynesty import DynamicNestedSampler, NestedSampler
from dynesty.plotting import runplot, traceplot, cornerplot
from dynesty.utils import resample_equal
import corner
from scipy import stats
from typing import Dict, List, Tuple, Optional, Callable
import logging
import warnings
import time
from multiprocessing import Pool, cpu_count

# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–∞—à–∏—Ç–µ –º–æ–¥—É–ª–∏
from mcmc_analysis import MCMCAnalysis
from observational_data import BAOObservationalData, CMBObservationalData, LikelihoodFunctions
from no_lambda_cosmology import NoLambdaCosmology
from fast_cosmo import *  # Numba –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏

# –ú–ò–ù–ò–ú–ê–õ–ù–û –ª–æ–≥–∏—Ä–∞–Ω–µ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

# –ü–æ—Ç–∏—Å–∫–∞–Ω–µ –Ω–∞ warnings
warnings.filterwarnings('ignore')

# –ì–ª–æ–±–∞–ª–Ω–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
C_KM_S = 299792.458  # km/s
PI = np.pi


class OptimizedNestedSampling:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω nested sampling –∫–ª–∞—Å –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç
    """
    
    def __init__(self, 
                 parameter_names: List[str] = None,
                 parameter_ranges: Dict[str, Tuple[float, float]] = None,
                 nlive: int = 100):  # –ü–æ-–º–∞–ª–∫–æ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
        """
        
        # –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –í–ï–î–ù–™–ñ
        self.bao_data = BAOObservationalData()
        self.cmb_data = CMBObservationalData()
        self.likelihood_func = LikelihoodFunctions(self.bao_data, self.cmb_data)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä–∏
        if parameter_names is None:
            parameter_names = ['H0', 'Omega_m', 'epsilon_bao', 'epsilon_cmb']  # üö® –ü–û–ü–†–ê–í–ö–ê: –î–æ–±–∞–≤–µ–Ω epsilon_cmb
        
        self.parameter_names = parameter_names
        self.n_params = len(parameter_names)
        
        # –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∏
        if parameter_ranges is None:
            parameter_ranges = {
                'H0': (65.0, 75.0),      # –ü–æ-—Ç–µ—Å–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω
                'Omega_m': (0.25, 0.35), # –ü–æ-—Ç–µ—Å–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω
                'epsilon_bao': (0.0, 0.05),
                'epsilon_cmb': (0.0, 0.05)  # üö® –ü–û–ü–†–ê–í–ö–ê: –î–æ–±–∞–≤–µ–Ω epsilon_cmb range
            }
        
        self.parameter_ranges = parameter_ranges
        
        # Nested sampling –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
        self.nlive = nlive
        self.dlogz = 0.5  # –ü–æ-–≥—Ä—É–±–∞ —Ç–æ—á–Ω–æ—Å—Ç –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
        self.maxiter = 1000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ
        
        # –ö–µ—à–∏—Ä–∞–Ω–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏
        self._setup_cached_data()
        
        # –†–µ–∑—É–ª—Ç–∞—Ç–∏
        self.sampler = None
        self.results = None
        
        print(f"‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–∞–Ω –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω nested sampling: {self.n_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, nlive={nlive}")
    
    def _setup_cached_data(self):
        """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª–Ω–æ –∫–µ—à–∏—Ä–∞–Ω–µ –Ω–∞ –¥–∞–Ω–Ω–∏ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç"""
        
        # üö® –ü–û–ü–†–ê–í–ö–ê: –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –Ω–æ–≤–∞—Ç–∞ create_bao_data —Ñ—É–Ω–∫—Ü–∏—è —Å –ø—ä–ª–Ω–∏ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏ –º–∞—Ç—Ä–∏—Ü–∏
        from observational_data import create_bao_data
        
        try:
            z_bao, DV_rs_obs, DV_rs_err, covariance_matrix = create_bao_data()
            
            self.cached_z_bao = z_bao
            self.cached_DV_rs_obs = DV_rs_obs
            self.cached_DV_rs_err = DV_rs_err
            self.cached_n_bao = len(z_bao)
            
            # –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ BAO
            if covariance_matrix is not None:
                self.cached_bao_cov_inv = np.linalg.inv(covariance_matrix)
                self.use_full_bao_covariance = True
                print("‚úÖ –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –ø—ä–ª–Ω–∞ BAO –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞")
            else:
                self.cached_bao_cov_inv = None
                self.use_full_bao_covariance = False
                print("‚ö†Ô∏è –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ BAO –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞")
                
        except Exception as e:
            print(f"‚ö†Ô∏è –ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ BAO –¥–∞–Ω–Ω–∏: {e}")
            # Fallback –∫—ä–º —Å—Ç–∞—Ä–∏—Ç–µ –¥–∞–Ω–Ω–∏
            bao_combined = self.bao_data.get_combined_data()
            self.cached_z_bao = bao_combined['redshifts']
            self.cached_DV_rs_obs = bao_combined['DV_rs']
            self.cached_DV_rs_err = bao_combined['DV_rs_err']
            self.cached_n_bao = len(self.cached_z_bao)
            self.cached_bao_cov_inv = None
            self.use_full_bao_covariance = False
        
        # –ö–µ—à–∏—Ä–∞–Ω–µ –Ω–∞ CMB –¥–∞–Ω–Ω–∏
        peak_data = self.cmb_data.get_peak_positions()
        acoustic_data = self.cmb_data.get_acoustic_scale()
        
        self.cached_l_peaks_obs = peak_data['l_peaks']
        self.cached_l_peaks_cov_inv = np.linalg.inv(peak_data['covariance'])
        
        self.cached_theta_s_obs = acoustic_data['theta_s']
        self.cached_theta_s_err = acoustic_data['theta_s_err']
        
        # –ü—Ä–µ–¥–∏–∑—á–∏—Å–ª–µ–Ω–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏
        self.cached_theta_s_var_inv = 1.0 / (self.cached_theta_s_err**2)
        
        print("‚úÖ –ö–µ—à–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
    
    def ptform(self, u: np.ndarray) -> np.ndarray:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω prior transform"""
        x = np.empty(self.n_params)
        
        for i, param_name in enumerate(self.parameter_names):
            param_min, param_max = self.parameter_ranges[param_name]
            x[i] = param_min + u[i] * (param_max - param_min)
        
        return x
    
    def loglike(self, params: np.ndarray) -> float:
        """–ü–û–ü–†–ê–í–ï–ù likelihood —Ñ—É–Ω–∫—Ü–∏—è —Å No-Lambda –º–æ–¥–µ–ª"""
        try:
            H0 = params[0]
            Omega_m = params[1]
            epsilon_bao = params[2] if len(params) > 2 else 0.0
            epsilon_cmb = params[3] if len(params) > 3 else 0.0

            # –ë—ä—Ä–∑–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if not (60 < H0 < 80 and 0.05 < Omega_m < 0.95):
                return -np.inf

            # üö® –ü–û–ü–†–ê–í–ö–ê: –ò–∑–ø–æ–ª–∑–≤–∞–º–µ –ø—ä–ª–Ω–∏—è No-Lambda –º–æ–¥–µ–ª —Å –ø–æ–ø—Ä–∞–≤–∫–∏—Ç–µ
            try:
                from no_lambda_cosmology import NoLambdaCosmology
                
                cosmo = NoLambdaCosmology(
                    H0=H0,
                    Omega_m=Omega_m,
                    epsilon_bao=epsilon_bao,
                    epsilon_cmb=epsilon_cmb
                )
                
                # BAO –∏–∑—á–∏—Å–ª–µ–Ω–∏—è —Å –ø–æ–ø—Ä–∞–≤–µ–Ω–∏—è –º–æ–¥–µ–ª –∏ –ø—ä–ª–Ω–∏ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏ –º–∞—Ç—Ä–∏—Ü–∏
                DV_rs_model = []
                for z in self.cached_z_bao:
                    # –ò–∑–ø–æ–ª–∑–≤–∞–º–µ –ø–æ–ø—Ä–∞–≤–µ–Ω–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏
                    D_A = cosmo.angular_diameter_distance(z)
                    H_z = cosmo.hubble_function(z)
                    D_H = C_KM_S / H_z
                    D_V = (z * D_A**2 * D_H)**(1/3.0)
                    r_s = cosmo.sound_horizon_scale()
                    
                    DV_rs_model.append(D_V / r_s)
                
                DV_rs_model = np.array(DV_rs_model)
                residuals_bao = self.cached_DV_rs_obs - DV_rs_model
                
                # Chi-squared –∏–∑—á–∏—Å–ª–µ–Ω–∏–µ —Å –æ–ø—Ü–∏—è –∑–∞ –ø—ä–ª–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
                if self.use_full_bao_covariance and self.cached_bao_cov_inv is not None:
                    # –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –ø—ä–ª–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
                    chi2_bao = residuals_bao.T @ self.cached_bao_cov_inv @ residuals_bao
                else:
                    # –î–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–µ–Ω –ø–æ–¥—Ö–æ–¥)
                    chi2_bao = np.sum((residuals_bao / self.cached_DV_rs_err)**2)
                
                # üö® –ü–û–ü–†–ê–í–ö–ê: CMB —Å –ø—Ä–∞–≤–∏–ª–Ω–∏—è angular_diameter_distance
                theta_s_model = cosmo.cmb_angular_scale()  # –ò–∑–ø–æ–ª–∑–≤–∞–º–µ –ø–æ–ø—Ä–∞–≤–µ–Ω–∞—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è
                residual_cmb = self.cached_theta_s_obs - theta_s_model
                chi2_cmb = (residual_cmb / self.cached_theta_s_err)**2

                # –û–±—â–∞ chi2
                total_chi2 = chi2_bao + chi2_cmb
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ NaN/inf
                if not np.isfinite(total_chi2):
                    return -np.inf
                    
                return -0.5 * total_chi2
                
            except Exception as e:
                # –ü—Ä–∏ –≥—Ä–µ—à–∫–∞ –≤ –∫–æ—Å–º–æ–ª–æ–≥–∏—è—Ç–∞, –≤—ä—Ä–Ω–∏ -inf
                return -np.inf
            
        except Exception:
            return -np.inf
    
    def run_fast_sampling(self, 
                         nlive: int = None,
                         dynamic: bool = False,  # Static –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
                         progress: bool = False,
                         parallel: bool = True) -> None:  # –î–æ–±–∞–≤—è–º–µ –æ–ø—Ü–∏—è –∑–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
        """
        –ú–∞–∫—Å–∏–º–∞–ª–Ω–æ –±—ä—Ä–∑ nested sampling —Å –æ–ø—Ü–∏—è –∑–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
        """
        
        if nlive is None:
            nlive = self.nlive
        
        print(f"üöÄ –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –ë–™–†–ó nested sampling: nlive={nlive}")
        start_time = time.time()
        
        if parallel:
            # –ò–∑–ø–æ–ª–∑–≤–∞–π –≤—Å–∏—á–∫–∏ –Ω–∞–ª–∏—á–Ω–∏ —è–¥—Ä–∞
            n_cpu = cpu_count()
            print(f"üî• –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è —Å {n_cpu} —è–¥—Ä–∞.")
            with Pool(processes=n_cpu) as pool:
                sampler = NestedSampler(
                    self.loglike,
                    self.ptform,
                    self.n_params,
                    nlive=nlive,
                    pool=pool,
                    queue_size=n_cpu
                )
                sampler.run_nested(print_progress=False)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–µ–Ω (—Å–µ—Ä–∏–µ–Ω) —Ä–µ–∂–∏–º
            sampler = NestedSampler(
                self.loglike,
                self.ptform,
                self.n_params,
                nlive=nlive
            )
            sampler.run_nested(print_progress=False)
        
        self.sampler = sampler
        self.results = sampler.results
        
        # –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ evidence
        self.log_evidence = self.results.logz[-1]
        self.log_evidence_err = self.results.logzerr[-1]
        
        # Posterior samples
        self.posterior_samples = resample_equal(
            self.results.samples,
            self.results.logwt
        )
        
        end_time = time.time()
        runtime = end_time - start_time
        
        print(f"‚úÖ Nested sampling –∑–∞–≤—ä—Ä—à–µ–Ω –∑–∞ {runtime:.1f}s")
        print(f"üìä Log-evidence: {self.log_evidence:.3f} ¬± {self.log_evidence_err:.3f}")
        print(f"üìà Samples: {len(self.posterior_samples)}")
        
        self._fast_analysis()
    
    def _fast_analysis(self):
        """–ë—ä—Ä–∑ –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
        
        if self.results is None:
            return
        
        # –ë—ä—Ä–∑–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.param_stats = {}
        
        for i, param_name in enumerate(self.parameter_names):
            samples = self.posterior_samples[:, i]
            
            mean_val = np.mean(samples)
            percentiles = np.percentile(samples, [16, 50, 84])
            
            self.param_stats[param_name] = {
                'mean': mean_val,
                'median': percentiles[1],
                'lower_err': percentiles[1] - percentiles[0],
                'upper_err': percentiles[2] - percentiles[1],
                'std': np.std(samples)
            }
        
        # Information criteria
        n_data = self.cached_n_bao + 4  # BAO + CMB –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª–Ω–æ
        best_log_like = np.max(self.results.logl)
        
        self.info_criteria = {
            'log_evidence': self.log_evidence,
            'log_evidence_err': self.log_evidence_err,
            'best_log_likelihood': best_log_like,
            'aic': 2 * self.n_params - 2 * best_log_like,
            'bic': np.log(n_data) * self.n_params - 2 * best_log_like,
            'n_parameters': self.n_params,
            'n_data': n_data
        }
    
    def quick_summary(self):
        """–ë—ä—Ä–∑–æ —Ä–µ–∑—é–º–µ –±–µ–∑ –º–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω–µ"""
        
        print("\n" + "="*50)
        print("üéØ –ë–™–†–ó NESTED SAMPLING –†–ï–ó–£–õ–¢–ê–¢–ò")
        print("="*50)
        
        if hasattr(self, 'log_evidence'):
            print(f"üìä Log-evidence: {self.log_evidence:.3f} ¬± {self.log_evidence_err:.3f}")
        
        if hasattr(self, 'info_criteria'):
            info = self.info_criteria
            print(f"üìà AIC: {info['aic']:.1f}")
            print(f"üìà BIC: {info['bic']:.1f}")
            print(f"üìà Best log-like: {info['best_log_likelihood']:.1f}")
        
        if hasattr(self, 'param_stats'):
            print(f"\nüîç –ü–ê–†–ê–ú–ï–¢–†–ò:")
            for param_name in self.parameter_names:
                if param_name in self.param_stats:
                    stats = self.param_stats[param_name]
                    print(f"  {param_name}: {stats['mean']:.4f} ¬± {stats['std']:.4f}")
    
    def save_results(self, filename: str = "fast_nested_results.npz"):
        """–ë—ä—Ä–∑–æ –∑–∞–ø–∏—Å–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
        
        if self.results is None:
            print("‚ùå –ù—è–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ")
            return
        
        np.savez(filename,
                samples=self.posterior_samples,
                logz=self.log_evidence,
                logz_err=self.log_evidence_err,
                param_names=self.parameter_names,
                param_stats=self.param_stats if hasattr(self, 'param_stats') else None
                )
        
        print(f"üíæ –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞–ø–∏—Å–∞–Ω–∏ –≤ {filename}")


def quick_test():
    """–ü–æ–µ—Ç–∞–ø–µ–Ω —Ç–µ—Å—Ç –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏—Ç–µ"""
    
    print("üß™ –ü–û–ï–¢–ê–ü–ï–ù –¢–ï–°–¢ –ù–ê –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò–¢–ï")
    print("="*50)
    
    # –°—Ç—ä–ø–∫–∞ 1: –¢–µ—Å—Ç —Å–∞–º–æ —Å Numba (–±–µ–∑ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è)
    print("\nüî• –°–¢–™–ü–ö–ê 1: –°–∞–º–æ Numba –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
    print("-"*30)
    
    ns = OptimizedNestedSampling(
        parameter_names=['H0', 'Omega_m'],  # –°–∞–º–æ 2 –ø–∞—Ä–∞–º–µ—Ç—ä—Ä–∞
        nlive=50  # –ú–∞–ª–∫–æ –∑–∞ –±—ä—Ä–∑ —Ç–µ—Å—Ç
    )
    
    print("‚è±Ô∏è –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ Numba —Ç–µ—Å—Ç (–º–æ–∂–µ –¥–∞ –æ—Ç–Ω–µ–º–µ 30-60s –∑–∞ –ø—ä—Ä–≤–∞ –∫–æ–º–ø–∏–ª–∞—Ü–∏—è)...")
    
    # –°–∞–º–æ Numba, –ë–ï–ó –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
    ns.run_fast_sampling(nlive=50, parallel=False, progress=False)
    
    print("‚úÖ Numba —Ç–µ—Å—Ç –∑–∞–≤—ä—Ä—à–∏!")
    ns.quick_summary()
    
    # –°—Ç—ä–ø–∫–∞ 2: –ê–∫–æ Numba —Ä–∞–±–æ—Ç–∏, —Ç–µ—Å—Ç —Å –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
    print("\nüöÄ –°–¢–™–ü–ö–ê 2: Numba + –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è")
    print("-"*30)
    
    try:
        ns2 = OptimizedNestedSampling(
            parameter_names=['H0', 'Omega_m'],
            nlive=50
        )
        
        print("‚è±Ô∏è –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∏—Ä–∞–Ω —Ç–µ—Å—Ç...")
        ns2.run_fast_sampling(nlive=50, parallel=True, progress=False)
        
        print("‚úÖ –ü–∞—Ä–∞–ª–µ–ª–∏–∑–∏—Ä–∞–Ω —Ç–µ—Å—Ç –∑–∞–≤—ä—Ä—à–∏!")
        ns2.quick_summary()
        
    except Exception as e:
        print(f"‚ùå –ü–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–µ —Ä–∞–±–æ—Ç–∏: {e}")
        print("‚ÑπÔ∏è –ù–æ Numba –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ —Ä–∞–±–æ—Ç–∏!")
    
    # –ó–∞–ø–∏—Å–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
    ns.save_results("numba_test_results.npz")
    
    print("\nüéâ –¢–µ—Å—Ç–æ–≤–µ—Ç–µ –∑–∞–≤—ä—Ä—à–∏—Ö–∞!")
    print("üí° –ê–∫–æ Numba —Ä–∞–±–æ—Ç–∏, –∏–º–∞—Ç–µ –ø–æ–Ω–µ 10x-50x —É—Å–∫–æ—Ä–µ–Ω–∏–µ!")


if __name__ == "__main__":
    quick_test() 