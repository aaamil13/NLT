#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω Nested Sampling –∞–Ω–∞–ª–∏–∑ –∑–∞ –º–æ–¥–µ–ª —Å–µ–ª–µ–∫—Ü–∏—è

–û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:
1. –ú–∏–Ω–∏–º–∞–ª–µ–Ω –∫–æ–Ω—Å–æ–ª–µ–Ω –∏–∑—Ö–æ–¥
2. –ö–µ—à–∏—Ä–∞–Ω–µ –Ω–∞ –∏–∑—á–∏—Å–ª–µ–Ω–∏—è
3. –í–µ–∫—Ç–æ—Ä–∏–∑–∏—Ä–∞–Ω–∏ –æ–ø–µ—Ä–∞—Ü–∏–∏
4. –ü–æ-–µ—Ñ–∏–∫–∞—Å–Ω–∏ likelihood —Ñ—É–Ω–∫—Ü–∏–∏
5. Numba –∫–æ–º–ø–∏–ª–∞—Ü–∏—è –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç
"""

import numpy as np
import matplotlib.pyplot as plt
from dynesty import DynamicNestedSampler, NestedSampler
from dynesty.plotting import runplot, traceplot, cornerplot
from dynesty.utils import resample_equal
import corner
from scipy import stats
from typing import Dict, List, Tuple, Optional, Callable
import logging
import warnings
import time
from multiprocessing import Pool, cpu_count

# –ò–º–ø–æ—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –Ω–∞—à–∏—Ç–µ –º–æ–¥—É–ª–∏
from mcmc_analysis import MCMCAnalysis
from observational_data import BAOObservationalData, CMBObservationalData, LikelihoodFunctions
from no_lambda_cosmology import NoLambdaCosmology
from fast_cosmo import *  # Numba –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–∏

# –ú–ò–ù–ò–ú–ê–õ–ù–û –ª–æ–≥–∏—Ä–∞–Ω–µ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)

# –ü–æ—Ç–∏—Å–∫–∞–Ω–µ –Ω–∞ warnings
warnings.filterwarnings('ignore')

# –ì–ª–æ–±–∞–ª–Ω–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∏ –∑–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
C_KM_S = 299792.458  # km/s
PI = np.pi


class OptimizedNestedSampling:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω nested sampling –∫–ª–∞—Å –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç
    """
    
    def __init__(self, 
                 parameter_names: List[str] = None,
                 parameter_ranges: Dict[str, Tuple[float, float]] = None,
                 nlive: int = 100,  # –ü–æ-–º–∞–ª–∫–æ –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
                 use_snia: bool = False,  # –û–ø—Ü–∏—è –∑–∞ SN Ia –¥–∞–Ω–Ω–∏
                 use_h0: bool = False):   # –û–ø—Ü–∏—è –∑–∞ H‚ÇÄ –¥–∞–Ω–Ω–∏
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω–∏—è nested sampling
        
        Args:
            parameter_names: –ò–º–µ–Ω–∞ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
            parameter_ranges: –î–∏–∞–ø–∞–∑–æ–Ω–∏ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
            nlive: –ë—Ä–æ–π live points
            use_snia: –î–∞–ª–∏ –¥–∞ —Å–µ –≤–∫–ª—é—á–∞—Ç SN Ia –¥–∞–Ω–Ω–∏
            use_h0: –î–∞–ª–∏ –¥–∞ —Å–µ –≤–∫–ª—é—á–∞—Ç H‚ÇÄ –¥–∞–Ω–Ω–∏
        """
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ
        self.use_snia = use_snia
        self.use_h0 = use_h0
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏—Ç–µ
        if parameter_names is None:
            parameter_names = ['H0', 'Omega_m', 'epsilon_bao', 'epsilon_cmb']
        
        if parameter_ranges is None:
            parameter_ranges = {
                'H0': (60.0, 80.0),
                'Omega_m': (0.05, 0.95),
                'epsilon_bao': (-0.1, 0.1),
                'epsilon_cmb': (-0.1, 0.1)
            }
        
        self.parameter_names = parameter_names
        self.parameter_ranges = parameter_ranges
        self.n_params = len(parameter_names)
        self.nlive = nlive
        
        # –ö–µ—à–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏
        self.cached_n_bao = 0
        self.cached_n_cmb = 0
        self.cached_n_snia = 0
        self.cached_n_h0 = 0
        
        # –†–µ–∑—É–ª—Ç–∞—Ç–∏
        self.results = None
        self.sampler = None
        self.log_evidence = None
        self.log_evidence_err = None
        self.posterior_samples = None
        self.param_stats = {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –¥–∞–Ω–Ω–∏—Ç–µ
        self._setup_cached_data()
        
        logger.info(f"–ù–∞—Å—Ç—Ä–æ–µ–Ω nested sampling —Å {self.n_params} –ø–∞—Ä–∞–º–µ—Ç—Ä–∞")
        
        # –ò–∑–±—Ä–æ–π –Ω–∞ –∞–∫—Ç–∏–≤–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏
        active_data = ['BAO', 'CMB']
        if self.use_snia:
            active_data.append('SN Ia')
        if self.use_h0:
            active_data.append('H‚ÇÄ')
        
        logger.info(f"–ê–∫—Ç–∏–≤–Ω–∏ –¥–∞–Ω–Ω–∏: {', '.join(active_data)}")
    
    def _setup_cached_data(self):
        """
        –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –∫–µ—à–∏—Ä–∞–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏ –∑–∞ –º–∞–∫—Å–∏–º–∞–ª–Ω–∞ —Å–∫–æ—Ä–æ—Å—Ç
        """
        logger.info("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–∞ –∫–µ—à–∏—Ä–∞–Ω–∏—Ç–µ –¥–∞–Ω–Ω–∏...")
        
        # –û—Å–Ω–æ–≤–Ω–∏ –¥–∞–Ω–Ω–∏ (BAO + CMB)
        from observational_data import (
            BAOObservationalData, 
            CMBObservationalData,
            SNIaObservationalData,
            LocalH0ObservationalData,
            LikelihoodFunctions
        )
        
        # –ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ BAO –∏ CMB –¥–∞–Ω–Ω–∏
        self.bao_data = BAOObservationalData()
        self.cmb_data = CMBObservationalData()
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ SN Ia –¥–∞–Ω–Ω–∏
        if self.use_snia:
            logger.info("–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ SN Ia –¥–∞–Ω–Ω–∏...")
            self.snia_data = SNIaObservationalData()
            self.cached_n_snia = len(self.snia_data.get_combined_data()['redshifts'])
            logger.info(f"–ó–∞—Ä–µ–¥–µ–Ω–∏ {self.cached_n_snia} SN Ia supernovae")
        else:
            self.snia_data = None
        
        # –û–ø—Ü–∏–æ–Ω–∞–ª–Ω–æ –∑–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ H‚ÇÄ –¥–∞–Ω–Ω–∏
        if self.use_h0:
            logger.info("–ó–∞—Ä–µ–∂–¥–∞–Ω–µ –Ω–∞ H‚ÇÄ –¥–∞–Ω–Ω–∏...")
            self.h0_data = LocalH0ObservationalData()
            self.cached_n_h0 = len(self.h0_data.h0_measurements)
            logger.info(f"–ó–∞—Ä–µ–¥–µ–Ω–∏ {self.cached_n_h0} H‚ÇÄ –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è")
        else:
            self.h0_data = None
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –ø—ä–ª–Ω–∞—Ç–∞ likelihood —Ñ—É–Ω–∫—Ü–∏—è
        self.likelihood_func = LikelihoodFunctions(
            bao_data=self.bao_data,
            cmb_data=self.cmb_data,
            snia_data=self.snia_data,
            h0_data=self.h0_data
        )
        
        # –ö–µ—à–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä–∏—Ç–µ
        self.cached_n_bao = len(self.bao_data.get_combined_data()['redshifts'])
        self.cached_n_cmb = 4  # theta_s + 3 peaks
        
        # –û–±—â –±—Ä–æ–π –¥–∞–Ω–Ω–∏
        total_data_points = self.cached_n_bao + self.cached_n_cmb + self.cached_n_snia + self.cached_n_h0
        logger.info(f"–û–±—â–æ –¥–∞–Ω–Ω–∏: {total_data_points} (BAO: {self.cached_n_bao}, CMB: {self.cached_n_cmb}, SN Ia: {self.cached_n_snia}, H‚ÇÄ: {self.cached_n_h0})")
        
        logger.info("–î–∞–Ω–Ω–∏—Ç–µ —Å–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏ –∏ –∫–µ—à–∏—Ä–∞–Ω–∏!")
    
    def ptform(self, u: np.ndarray) -> np.ndarray:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–∞–Ω prior transform"""
        x = np.empty(self.n_params)
        
        for i, param_name in enumerate(self.parameter_names):
            param_min, param_max = self.parameter_ranges[param_name]
            x[i] = param_min + u[i] * (param_max - param_min)
        
        return x
    
    def loglike(self, params: np.ndarray) -> float:
        """–ü–™–õ–ï–ù Cross-validation likelihood —Ñ—É–Ω–∫—Ü–∏—è —Å BAO + CMB + SN Ia + H‚ÇÄ"""
        try:
            H0 = params[0]
            Omega_m = params[1]
            epsilon_bao = params[2] if len(params) > 2 else 0.0
            epsilon_cmb = params[3] if len(params) > 3 else 0.0

            # –ë—ä—Ä–∑–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if not (60 < H0 < 80 and 0.05 < Omega_m < 0.95):
                return -np.inf

            # üö® –ü–û–ü–†–ê–í–ö–ê: –ò–∑–ø–æ–ª–∑–≤–∞–º–µ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–µ–Ω No-Lambda –º–æ–¥–µ–ª
            try:
                from no_lambda_cosmology import NoLambdaCosmology
                
                cosmo = NoLambdaCosmology(
                    H0=H0,
                    Omega_m=Omega_m,
                    epsilon_bao=epsilon_bao,
                    epsilon_cmb=epsilon_cmb,
                    alpha=1.2,
                    beta=0.0,
                    gamma=0.4,
                    delta=0.08,
                    angular_strength=0.6
                )
                
                # BAO –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏)
                bao_combined = self.bao_data.get_combined_data()
                z_bao = bao_combined['redshifts']
                
                # –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏ BAO –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                bao_predictions = cosmo.calculate_bao_predictions(z_bao)
                
                # CMB –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                theta_s_pred = cosmo.cmb_angular_scale()
                l_peaks_pred = np.array([
                    cosmo.cmb_peak_position(),
                    cosmo.cmb_peak_position() * 1.4,
                    cosmo.cmb_peak_position() * 2.1
                ])
                
                cmb_predictions = {
                    'theta_s': theta_s_pred,
                    'l_peaks': l_peaks_pred
                }
                
                # SN Ia –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–∞–∫–æ —Å–∞ –Ω–∞–ª–∏—á–Ω–∏)
                snia_predictions = {}
                if hasattr(self, 'snia_data') and self.snia_data is not None:
                    snia_combined = self.snia_data.get_combined_data()
                    z_snia = snia_combined['redshifts']
                    
                    # Distance modulus –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                    mu_pred = cosmo.distance_modulus(z_snia)
                    snia_predictions['distance_modulus'] = mu_pred
                
                # H‚ÇÄ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–∞–∫–æ —Å–∞ –Ω–∞–ª–∏—á–Ω–∏)
                h0_predictions = {}
                if hasattr(self, 'h0_data') and self.h0_data is not None:
                    h0_pred = cosmo.h0_prediction()
                    h0_predictions['H0'] = h0_pred['H0']
                
                # –û–±–µ–¥–∏–Ω–µ–Ω–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                combined_predictions = {
                    **bao_predictions,
                    **cmb_predictions,
                    **snia_predictions,
                    **h0_predictions
                }
                
                # –ü—ä–ª–µ–Ω likelihood –æ—Ç –≤—Å–∏—á–∫–∏ –¥–∞–Ω–Ω–∏
                total_loglike = 0.0
                
                # BAO likelihood
                bao_loglike = self.likelihood_func.bao_likelihood(combined_predictions, use_anisotropic=True)
                total_loglike += bao_loglike
                
                # CMB likelihood
                cmb_loglike = self.likelihood_func.cmb_likelihood(combined_predictions)
                total_loglike += cmb_loglike
                
                # SN Ia likelihood (–∞–∫–æ –µ –Ω–∞–ª–∏—á–Ω–æ)
                if hasattr(self, 'snia_data') and self.snia_data is not None:
                    snia_loglike = self.likelihood_func.snia_likelihood(combined_predictions)
                    total_loglike += snia_loglike
                
                # H‚ÇÄ likelihood (–∞–∫–æ –µ –Ω–∞–ª–∏—á–Ω–æ)
                if hasattr(self, 'h0_data') and self.h0_data is not None:
                    h0_loglike = self.likelihood_func.h0_likelihood(combined_predictions)
                    total_loglike += h0_loglike
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç
                if np.isnan(total_loglike) or np.isinf(total_loglike):
                    return -np.inf
                
                return total_loglike
                
            except Exception as e:
                logger.warning(f"–ì—Ä–µ—à–∫–∞ –≤ –∫–æ—Å–º–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—è –º–æ–¥–µ–ª: {e}")
                return -np.inf
                
        except Exception as e:
            logger.warning(f"–ì—Ä–µ—à–∫–∞ –≤ likelihood —Ñ—É–Ω–∫—Ü–∏—è—Ç–∞: {e}")
            return -np.inf
    
    def run_fast_sampling(self, 
                         nlive: int = None,
                         dynamic: bool = False,  # Static –∑–∞ —Å–∫–æ—Ä–æ—Å—Ç
                         progress: bool = False,
                         parallel: bool = True) -> None:  # –î–æ–±–∞–≤—è–º–µ –æ–ø—Ü–∏—è –∑–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
        """
        –ú–∞–∫—Å–∏–º–∞–ª–Ω–æ –±—ä—Ä–∑ nested sampling —Å –æ–ø—Ü–∏—è –∑–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
        """
        
        if nlive is None:
            nlive = self.nlive
        
        print(f"üöÄ –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –ë–™–†–ó nested sampling: nlive={nlive}")
        start_time = time.time()
        
        if parallel:
            # –ò–∑–ø–æ–ª–∑–≤–∞–π –≤—Å–∏—á–∫–∏ –Ω–∞–ª–∏—á–Ω–∏ —è–¥—Ä–∞
            n_cpu = cpu_count()
            print(f"üî• –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è —Å {n_cpu} —è–¥—Ä–∞.")
            with Pool(processes=n_cpu) as pool:
                sampler = NestedSampler(
                    self.loglike,
                    self.ptform,
                    self.n_params,
                    nlive=nlive,
                    pool=pool,
                    queue_size=n_cpu
                )
                sampler.run_nested(print_progress=False)
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–µ–Ω (—Å–µ—Ä–∏–µ–Ω) —Ä–µ–∂–∏–º
            sampler = NestedSampler(
                self.loglike,
                self.ptform,
                self.n_params,
                nlive=nlive
            )
            sampler.run_nested(print_progress=False)
        
        self.sampler = sampler
        self.results = sampler.results
        
        # –ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ evidence
        self.log_evidence = self.results.logz[-1]
        self.log_evidence_err = self.results.logzerr[-1]
        
        # Posterior samples
        self.posterior_samples = resample_equal(
            self.results.samples,
            self.results.logwt
        )
        
        end_time = time.time()
        runtime = end_time - start_time
        
        print(f"‚úÖ Nested sampling –∑–∞–≤—ä—Ä—à–µ–Ω –∑–∞ {runtime:.1f}s")
        print(f"üìä Log-evidence: {self.log_evidence:.3f} ¬± {self.log_evidence_err:.3f}")
        print(f"üìà Samples: {len(self.posterior_samples)}")
        
        self._fast_analysis()
    
    def _fast_analysis(self):
        """–ë—ä—Ä–∑ –∞–Ω–∞–ª–∏–∑ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
        
        if self.results is None:
            return
        
        # –ë—ä—Ä–∑–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.param_stats = {}
        
        for i, param_name in enumerate(self.parameter_names):
            samples = self.posterior_samples[:, i]
            
            mean_val = np.mean(samples)
            percentiles = np.percentile(samples, [16, 50, 84])
            
            self.param_stats[param_name] = {
                'mean': mean_val,
                'median': percentiles[1],
                'lower_err': percentiles[1] - percentiles[0],
                'upper_err': percentiles[2] - percentiles[1],
                'std': np.std(samples)
            }
        
        # Information criteria
        n_data = self.cached_n_bao + self.cached_n_cmb + self.cached_n_snia + self.cached_n_h0
        best_log_like = np.max(self.results.logl)
        
        self.info_criteria = {
            'log_evidence': self.log_evidence,
            'log_evidence_err': self.log_evidence_err,
            'best_log_likelihood': best_log_like,
            'aic': 2 * self.n_params - 2 * best_log_like,
            'bic': np.log(n_data) * self.n_params - 2 * best_log_like,
            'n_parameters': self.n_params,
            'n_data': n_data
        }
    
    def quick_summary(self):
        """–ë—ä—Ä–∑–æ —Ä–µ–∑—é–º–µ –±–µ–∑ –º–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–∞–Ω–µ"""
        
        print("\n" + "="*50)
        print("üéØ –ë–™–†–ó NESTED SAMPLING –†–ï–ó–£–õ–¢–ê–¢–ò")
        print("="*50)
        
        if hasattr(self, 'log_evidence'):
            print(f"üìä Log-evidence: {self.log_evidence:.3f} ¬± {self.log_evidence_err:.3f}")
        
        if hasattr(self, 'info_criteria'):
            info = self.info_criteria
            print(f"üìà AIC: {info['aic']:.1f}")
            print(f"üìà BIC: {info['bic']:.1f}")
            print(f"üìà Best log-like: {info['best_log_likelihood']:.1f}")
        
        if hasattr(self, 'param_stats'):
            print(f"\nüîç –ü–ê–†–ê–ú–ï–¢–†–ò:")
            for param_name in self.parameter_names:
                if param_name in self.param_stats:
                    stats = self.param_stats[param_name]
                    print(f"  {param_name}: {stats['mean']:.4f} ¬± {stats['std']:.4f}")
    
    def save_results(self, filename: str = "fast_nested_results.npz"):
        """–ë—ä—Ä–∑–æ –∑–∞–ø–∏—Å–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ"""
        
        if self.results is None:
            print("‚ùå –ù—è–º–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞ –∑–∞–ø–∏—Å–≤–∞–Ω–µ")
            return
        
        np.savez(filename,
                samples=self.posterior_samples,
                logz=self.log_evidence,
                logz_err=self.log_evidence_err,
                param_names=self.parameter_names,
                param_stats=self.param_stats if hasattr(self, 'param_stats') else None
                )
        
        print(f"üíæ –†–µ–∑—É–ª—Ç–∞—Ç–∏ –∑–∞–ø–∏—Å–∞–Ω–∏ –≤ {filename}")


def quick_test():
    """–ü–æ–µ—Ç–∞–ø–µ–Ω —Ç–µ—Å—Ç –Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏—Ç–µ"""
    
    print("üß™ –ü–û–ï–¢–ê–ü–ï–ù –¢–ï–°–¢ –ù–ê –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò–¢–ï")
    print("="*50)
    
    # –°—Ç—ä–ø–∫–∞ 1: –¢–µ—Å—Ç —Å–∞–º–æ —Å Numba (–±–µ–∑ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è)
    print("\nüî• –°–¢–™–ü–ö–ê 1: –°–∞–º–æ Numba –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è")
    print("-"*30)
    
    ns = OptimizedNestedSampling(
        parameter_names=['H0', 'Omega_m'],  # –°–∞–º–æ 2 –ø–∞—Ä–∞–º–µ—Ç—ä—Ä–∞
        nlive=50  # –ú–∞–ª–∫–æ –∑–∞ –±—ä—Ä–∑ —Ç–µ—Å—Ç
    )
    
    print("‚è±Ô∏è –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ Numba —Ç–µ—Å—Ç (–º–æ–∂–µ –¥–∞ –æ—Ç–Ω–µ–º–µ 30-60s –∑–∞ –ø—ä—Ä–≤–∞ –∫–æ–º–ø–∏–ª–∞—Ü–∏—è)...")
    
    # –°–∞–º–æ Numba, –ë–ï–ó –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
    ns.run_fast_sampling(nlive=50, parallel=False, progress=False)
    
    print("‚úÖ Numba —Ç–µ—Å—Ç –∑–∞–≤—ä—Ä—à–∏!")
    ns.quick_summary()
    
    # –°—Ç—ä–ø–∫–∞ 2: –ê–∫–æ Numba —Ä–∞–±–æ—Ç–∏, —Ç–µ—Å—Ç —Å –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è
    print("\nüöÄ –°–¢–™–ü–ö–ê 2: Numba + –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è")
    print("-"*30)
    
    try:
        ns2 = OptimizedNestedSampling(
            parameter_names=['H0', 'Omega_m'],
            nlive=50
        )
        
        print("‚è±Ô∏è –°—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –ø–∞—Ä–∞–ª–µ–ª–∏–∑–∏—Ä–∞–Ω —Ç–µ—Å—Ç...")
        ns2.run_fast_sampling(nlive=50, parallel=True, progress=False)
        
        print("‚úÖ –ü–∞—Ä–∞–ª–µ–ª–∏–∑–∏—Ä–∞–Ω —Ç–µ—Å—Ç –∑–∞–≤—ä—Ä—à–∏!")
        ns2.quick_summary()
        
    except Exception as e:
        print(f"‚ùå –ü–∞—Ä–∞–ª–µ–ª–∏–∑–∞—Ü–∏—è—Ç–∞ –Ω–µ —Ä–∞–±–æ—Ç–∏: {e}")
        print("‚ÑπÔ∏è –ù–æ Numba –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ç–∞ —Ä–∞–±–æ—Ç–∏!")
    
    # –ó–∞–ø–∏—Å–≤–∞–Ω–µ –Ω–∞ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏—Ç–µ
    ns.save_results("numba_test_results.npz")
    
    print("\nüéâ –¢–µ—Å—Ç–æ–≤–µ—Ç–µ –∑–∞–≤—ä—Ä—à–∏—Ö–∞!")
    print("üí° –ê–∫–æ Numba —Ä–∞–±–æ—Ç–∏, –∏–º–∞—Ç–µ –ø–æ–Ω–µ 10x-50x —É—Å–∫–æ—Ä–µ–Ω–∏–µ!")


if __name__ == "__main__":
    quick_test() 