#!/usr/bin/env python3
"""
BAO –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏ –º–∞—Ç—Ä–∏—Ü–∏
–¶–µ–ª: –ò–º–ø–ª–µ–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ –ø—ä–ª–Ω–∏ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏ –º–∞—Ç—Ä–∏—Ü–∏ –∑–∞ BAO –¥–∞–Ω–Ω–∏
–ë–∞–∑–∏—Ä–∞–Ω–æ –Ω–∞: BOSS DR12, eBOSS DR16 –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
"""

import numpy as np
import logging
from typing import Dict, List, Tuple

logger = logging.getLogger(__name__)

class BAOCovarianceMatrices:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∏ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏ –º–∞—Ç—Ä–∏—Ü–∏ –∑–∞ BAO –¥–∞–Ω–Ω–∏
    –ë–∞–∑–∏—Ä–∞–Ω–æ –Ω–∞ –ø—É–±–ª–∏–∫—É–≤–∞–Ω–∏ BOSS –∏ eBOSS –∫–æ—Ä–µ–ª–∞—Ü–∏–∏
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏—Ç–µ –º–∞—Ç—Ä–∏—Ü–∏"""
        self.covariance_matrices = {}
        self._generate_boss_covariance()
        self._generate_eboss_covariance()
        self._generate_combined_covariance()
        
        logger.info("–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–∏ BAO –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏ –º–∞—Ç—Ä–∏—Ü–∏")
    
    def _generate_boss_covariance(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ BOSS DR12 –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞"""
        
        # BOSS DR12 z —Ç–æ—á–∫–∏
        z_boss = np.array([0.380, 0.510, 0.610])
        n_boss = len(z_boss)
        
        # –î–∏–∞–≥–æ–Ω–∞–ª–Ω–∏ –≥—Ä–µ—à–∫–∏ (–æ—Ç –Ω–∞–±–ª—é–¥–µ–Ω–∏—è)
        diag_errors = np.array([0.787, 0.902, 1.226])  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –±–∞–∑–æ–≤–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        cov_boss = np.diag(diag_errors**2)
        
        # –î–æ–±–∞–≤—è–Ω–µ –Ω–∞ –∫–æ—Ä–µ–ª–∞—Ü–∏–∏ –º–µ–∂–¥—É —Å—ä—Å–µ–¥–Ω–∏ z —Ç–æ—á–∫–∏
        # –ë–∞–∑–∏—Ä–∞–Ω–æ –Ω–∞ —Å–ø–æ–¥–µ–ª–µ–Ω–∏ –≥–∞–ª–∞–∫—Ç–∏–∫–∏ –∏ –∫–æ—Å–º–∏—á–µ—Å–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
        correlation_matrix = np.array([
            [1.00, 0.25, 0.10],  # z=0.38 –∫–æ—Ä–µ–ª–∏—Ä–∞ —Å 0.51 (25%), 0.61 (10%)
            [0.25, 1.00, 0.35],  # z=0.51 –∫–æ—Ä–µ–ª–∏—Ä–∞ —Å 0.38 (25%), 0.61 (35%)
            [0.10, 0.35, 1.00]   # z=0.61 –∫–æ—Ä–µ–ª–∏—Ä–∞ —Å 0.38 (10%), 0.51 (35%)
        ])
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–Ω–µ –∫—ä–º –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        for i in range(n_boss):
            for j in range(n_boss):
                if i != j:
                    cov_boss[i, j] = correlation_matrix[i, j] * np.sqrt(cov_boss[i, i] * cov_boss[j, j])
        
        self.covariance_matrices['BOSS_DR12'] = {
            'redshifts': z_boss,
            'covariance': cov_boss,
            'correlation': correlation_matrix,
            'description': 'BOSS DR12 DV/rs –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞'
        }
        
        logger.info(f"BOSS DR12 –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞: {n_boss}x{n_boss}")
    
    def _generate_eboss_covariance(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ eBOSS DR16 –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞"""
        
        # eBOSS DR16 z —Ç–æ—á–∫–∏
        z_eboss = np.array([0.700, 0.850, 1.480])
        n_eboss = len(z_eboss)
        
        # –î–∏–∞–≥–æ–Ω–∞–ª–Ω–∏ –≥—Ä–µ—à–∫–∏
        diag_errors = np.array([1.601, 1.709, 1.802])  # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª–Ω–∏ —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –±–∞–∑–æ–≤–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        cov_eboss = np.diag(diag_errors**2)
        
        # eBOSS –∫–æ—Ä–µ–ª–∞—Ü–∏–∏ (–ø–æ-—Å–ª–∞–±–∏ –∑–∞—Ä–∞–¥–∏ –ø–æ-–≥–æ–ª–µ–º–∏ —Ä–∞–∑—Å—Ç–æ—è–Ω–∏—è)
        correlation_matrix = np.array([
            [1.00, 0.15, 0.05],  # z=0.70 –∫–æ—Ä–µ–ª–∏—Ä–∞ —Å 0.85 (15%), 1.48 (5%)
            [0.15, 1.00, 0.20],  # z=0.85 –∫–æ—Ä–µ–ª–∏—Ä–∞ —Å 0.70 (15%), 1.48 (20%)
            [0.05, 0.20, 1.00]   # z=1.48 –∫–æ—Ä–µ–ª–∏—Ä–∞ —Å 0.70 (5%), 0.85 (20%)
        ])
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–≤–∞–Ω–µ –∫—ä–º –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        for i in range(n_eboss):
            for j in range(n_eboss):
                if i != j:
                    cov_eboss[i, j] = correlation_matrix[i, j] * np.sqrt(cov_eboss[i, i] * cov_eboss[j, j])
        
        self.covariance_matrices['eBOSS_DR16'] = {
            'redshifts': z_eboss,
            'covariance': cov_eboss,
            'correlation': correlation_matrix,
            'description': 'eBOSS DR16 DV/rs –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞'
        }
        
        logger.info(f"eBOSS DR16 –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞: {n_eboss}x{n_eboss}")
    
    def _generate_combined_covariance(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–º–±–∏–Ω–∏—Ä–∞–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ –≤—Å–∏—á–∫–∏ BAO –¥–∞–Ω–Ω–∏"""
        
        # –í—Å–∏—á–∫–∏ z —Ç–æ—á–∫–∏ –æ—Ç –≤—Å–∏—á–∫–∏ surveys
        z_all = np.array([
            # BOSS DR12
            0.38, 0.51, 0.61,
            # eBOSS DR16
            0.70, 0.85, 1.48,
            # 6dFGS
            0.106,
            # WiggleZ
            0.44, 0.60, 0.73
        ])
        
        # –î–∏–∞–≥–æ–Ω–∞–ª–Ω–∏ –≥—Ä–µ—à–∫–∏ –∑–∞ –≤—Å–∏—á–∫–∏ —Ç–æ—á–∫–∏
        diag_errors = np.array([
            # BOSS DR12
            0.38, 0.45, 0.51,
            # eBOSS DR16
            0.54, 0.64, 0.75,
            # 6dFGS
            0.29,
            # WiggleZ
            0.85, 1.07, 1.31
        ])
        
        n_all = len(z_all)
        
        # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –±–∞–∑–æ–≤–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        cov_combined = np.diag(diag_errors**2)
        
        # –ö–æ—Ä–µ–ª–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ –≤—Å–∏—á–∫–∏ —Ç–æ—á–∫–∏
        correlation_matrix = np.eye(n_all)
        
        for i in range(n_all):
            for j in range(n_all):
                if i != j:
                    z_separation = abs(z_all[i] - z_all[j])
                    
                    # –ö–æ—Ä–µ–ª–∞—Ü–∏—è—Ç–∞ –∑–∞–≤–∏—Å–∏ –æ—Ç –±–ª–∏–∑–æ—Å—Ç—Ç–∞ –≤ z –∏ survey
                    if z_separation < 0.1:
                        correlation = 0.4 * np.exp(-z_separation / 0.05)
                    elif z_separation < 0.3:
                        correlation = 0.3 * np.exp(-z_separation / 0.1)
                    elif z_separation < 0.6:
                        correlation = 0.2 * np.exp(-z_separation / 0.2)
                    else:
                        correlation = 0.1 * np.exp(-z_separation / 0.4)
                    
                    # –°–ø–µ—Ü–∏–∞–ª–Ω–∏ –∫–æ—Ä–µ–ª–∞—Ü–∏–∏ –∑–∞ —Å—ä—â–∏—Ç–µ surveys
                    if self._same_survey(i, j):
                        correlation *= 1.5  # –ü–æ-—Å–∏–ª–Ω–∞ –∫–æ—Ä–µ–ª–∞—Ü–∏—è –≤ —Å—ä—â–∏—è survey
                    
                    correlation_matrix[i, j] = correlation
                    
                    # –î–æ–±–∞–≤—è–Ω–µ –Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏—è—Ç–∞
                    cov_combined[i, j] = correlation * np.sqrt(cov_combined[i, i] * cov_combined[j, j])
        
        self.covariance_matrices['Combined'] = {
            'redshifts': z_all,
            'covariance': cov_combined,
            'correlation': correlation_matrix,
            'description': '–ö–æ–º–±–∏–Ω–∏—Ä–∞–Ω–∞ BAO –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ (–≤—Å–∏—á–∫–∏ 10 —Ç–æ—á–∫–∏)'
        }
        
        logger.info(f"–ö–æ–º–±–∏–Ω–∏—Ä–∞–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞: {n_all}x{n_all}")
    
    def _same_survey(self, i: int, j: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–ª–∏ –¥–≤–µ —Ç–æ—á–∫–∏ —Å–∞ –æ—Ç —Å—ä—â–∏—è survey"""
        
        # –ò–Ω–¥–µ–∫—Å–∏ –Ω–∞ surveys:
        # BOSS DR12: 0, 1, 2
        # eBOSS DR16: 3, 4, 5
        # 6dFGS: 6
        # WiggleZ: 7, 8, 9
        
        boss_indices = [0, 1, 2]
        eboss_indices = [3, 4, 5]
        sidf_indices = [6]
        wigglez_indices = [7, 8, 9]
        
        return (
            (i in boss_indices and j in boss_indices) or
            (i in eboss_indices and j in eboss_indices) or
            (i in sidf_indices and j in sidf_indices) or
            (i in wigglez_indices and j in wigglez_indices)
        )
    
    def get_full_covariance_matrix(self, survey_name: str = 'Combined') -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ –ø—ä–ª–Ω–∞—Ç–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ –¥–∞–¥–µ–Ω survey
        
        Args:
            survey_name: –ò–º–µ –Ω–∞ –ø—Ä–æ—É—á–≤–∞–Ω–µ—Ç–æ ('Combined', 'BOSS_DR12', 'eBOSS_DR16')
            
        Returns:
            –ü—ä–ª–Ω–∞—Ç–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        """
        
        if survey_name not in self.covariance_matrices:
            logger.warning(f"Survey '{survey_name}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω. –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ 'Combined'.")
            survey_name = 'Combined'
        
        return self.covariance_matrices[survey_name]['covariance']
    
    def get_redshifts(self, survey_name: str = 'Combined') -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ redshift —Å—Ç–æ–π–Ω–æ—Å—Ç–∏—Ç–µ –∑–∞ –¥–∞–¥–µ–Ω survey
        
        Args:
            survey_name: –ò–º–µ –Ω–∞ –ø—Ä–æ—É—á–≤–∞–Ω–µ—Ç–æ
            
        Returns:
            Redshift —Å—Ç–æ–π–Ω–æ—Å—Ç–∏
        """
        
        if survey_name not in self.covariance_matrices:
            logger.warning(f"Survey '{survey_name}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω. –ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ 'Combined'.")
            survey_name = 'Combined'
        
        return self.covariance_matrices[survey_name]['redshifts']
    
    def get_diagonal_errors(self, survey_name: str = 'Combined') -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∏—Ç–µ –≥—Ä–µ—à–∫–∏ –æ—Ç –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—Ç–∞ –º–∞—Ç—Ä–∏—Ü–∞
        
        Args:
            survey_name: –ò–º–µ –Ω–∞ –ø—Ä–æ—É—á–≤–∞–Ω–µ—Ç–æ
            
        Returns:
            –î–∏–∞–≥–æ–Ω–∞–ª–Ω–∏ –≥—Ä–µ—à–∫–∏
        """
        
        covariance = self.get_full_covariance_matrix(survey_name)
        return np.sqrt(np.diag(covariance))
    
    def validate_covariance_matrix(self, survey_name: str = 'Combined') -> Dict:
        """
        –í–∞–ª–∏–¥–∏—Ä–∞–Ω–µ –Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—Ç–∞ –º–∞—Ç—Ä–∏—Ü–∞
        
        Args:
            survey_name: –ò–º–µ –Ω–∞ –ø—Ä–æ—É—á–≤–∞–Ω–µ—Ç–æ
            
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –≤–∞–ª–∏–¥–∏—Ä–∞–Ω–µ
        """
        
        covariance = self.get_full_covariance_matrix(survey_name)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª–Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ—Å—Ç
        eigenvalues = np.linalg.eigvals(covariance)
        is_positive_definite = np.all(eigenvalues > 0)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç
        is_symmetric = np.allclose(covariance, covariance.T)
        
        # Condition number
        condition_number = np.linalg.cond(covariance)
        
        # Determinant
        determinant = np.linalg.det(covariance)
        
        return {
            'is_positive_definite': is_positive_definite,
            'is_symmetric': is_symmetric,
            'condition_number': condition_number,
            'determinant': determinant,
            'min_eigenvalue': np.min(eigenvalues),
            'max_eigenvalue': np.max(eigenvalues),
            'matrix_shape': covariance.shape
        }

    def get_covariance_matrix(self, survey_name: str) -> Dict:
        """–ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –ø—Ä–æ—É—á–≤–∞–Ω–µ"""
        if survey_name not in self.covariance_matrices:
            available = list(self.covariance_matrices.keys())
            raise ValueError(f"–ü—Ä–æ—É—á–≤–∞–Ω–µ '{survey_name}' –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω–æ. –ù–∞–ª–∏—á–Ω–∏: {available}")
        
        return self.covariance_matrices[survey_name]
    
    def compute_chi_squared(self, survey_name: str, observed: np.ndarray, predicted: np.ndarray) -> float:
        """–ò–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ œá¬≤ —Å –ø—ä–ª–Ω–∞—Ç–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞"""
        
        cov_data = self.get_covariance_matrix(survey_name)
        cov_matrix = cov_data['covariance']
        
        # –†–µ–∑–∏–¥—É–∞–ª–∏
        residuals = observed - predicted
        
        # œá¬≤ = r^T * C^-1 * r
        try:
            cov_inv = np.linalg.inv(cov_matrix)
            chi_squared = np.dot(residuals, np.dot(cov_inv, residuals))
            return chi_squared
        except np.linalg.LinAlgError:
            logger.warning(f"–°–∏–Ω–≥—É–ª—è—Ä–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ {survey_name}")
            # Fallback –∫—ä–º –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
            diag_errors = np.sqrt(np.diag(cov_matrix))
            chi_squared = np.sum((residuals / diag_errors)**2)
            return chi_squared
    
    def generate_anisotropic_covariance(self, survey_name: str) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä–∞–Ω–µ –Ω–∞ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ DA/rs –∏ DH/rs"""
        
        base_cov = self.get_covariance_matrix(survey_name)
        z_points = base_cov['redshifts']
        n_points = len(z_points)
        
        # 2x2 –±–ª–æ–∫ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ –≤—Å—è–∫–∞ z —Ç–æ—á–∫–∞ (DA/rs, DH/rs)
        aniso_cov = np.zeros((2 * n_points, 2 * n_points))
        
        # –î–∏–∞–≥–æ–Ω–∞–ª–Ω–∏ –≥—Ä–µ—à–∫–∏ –∑–∞ DA/rs –∏ DH/rs
        da_rs_errors = np.sqrt(np.diag(base_cov['covariance'])) * 0.8  # DA/rs –ø–æ-—Ç–æ—á–Ω–æ
        dh_rs_errors = np.sqrt(np.diag(base_cov['covariance'])) * 1.2  # DH/rs –ø–æ-–Ω–µ—Ç–æ—á–Ω–æ
        
        for i in range(n_points):
            for j in range(n_points):
                # DA/rs - DA/rs –±–ª–æ–∫
                aniso_cov[2*i, 2*j] = base_cov['covariance'][i, j] * 0.64  # 0.8^2
                
                # DH/rs - DH/rs –±–ª–æ–∫
                aniso_cov[2*i+1, 2*j+1] = base_cov['covariance'][i, j] * 1.44  # 1.2^2
                
                # DA/rs - DH/rs –∫—Ä—ä—Å—Ç–æ—Å–∞–Ω–∞ –∫–æ—Ä–µ–ª–∞—Ü–∏—è
                if i == j:
                    cross_correlation = -0.4  # –ê–Ω—Ç–∏-–∫–æ—Ä–µ–ª–∞—Ü–∏—è
                else:
                    cross_correlation = 0.1 * base_cov['correlation'][i, j]
                
                aniso_cov[2*i, 2*j+1] = cross_correlation * da_rs_errors[i] * dh_rs_errors[j]
                aniso_cov[2*i+1, 2*j] = cross_correlation * dh_rs_errors[i] * da_rs_errors[j]
        
        return {
            'redshifts': z_points,
            'covariance': aniso_cov,
            'da_rs_errors': da_rs_errors,
            'dh_rs_errors': dh_rs_errors,
            'description': f'–ê–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ {survey_name}'
        }
    
    def summary(self):
        """–†–µ–∑—é–º–µ –Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏—Ç–µ –º–∞—Ç—Ä–∏—Ü–∏"""
        print("üìä BAO –ö–û–í–ê–†–ò–ê–¶–ò–û–ù–ù–ò –ú–ê–¢–†–ò–¶–ò")
        print("=" * 50)
        
        for survey_name, data in self.covariance_matrices.items():
            print(f"\n{survey_name}:")
            print(f"  –û–ø–∏—Å–∞–Ω–∏–µ: {data['description']}")
            print(f"  z —Ç–æ—á–∫–∏: {len(data['redshifts'])}")
            print(f"  z –¥–∏–∞–ø–∞–∑–æ–Ω: {data['redshifts'][0]:.2f} - {data['redshifts'][-1]:.2f}")
            print(f"  –ú–∞—Ç—Ä–∏—Ü–∞: {data['covariance'].shape}")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∑–∞ –∫–æ—Ä–µ–ª–∞—Ü–∏—è—Ç–∞
            corr_matrix = data['correlation']
            off_diagonal = corr_matrix[np.triu_indices_from(corr_matrix, k=1)]
            
            print(f"  –ö–æ—Ä–µ–ª–∞—Ü–∏–∏: {np.min(off_diagonal):.3f} - {np.max(off_diagonal):.3f}")
            print(f"  –°—Ä–µ–¥–Ω–∞ –∫–æ—Ä–µ–ª–∞—Ü–∏—è: {np.mean(off_diagonal):.3f}")
            
            # Condition number
            condition_number = np.linalg.cond(data['covariance'])
            print(f"  Condition number: {condition_number:.2e}")

    def get_dataset_covariance_matrix(self, dataset_name: str, n_measurements: int) -> np.ndarray:
        """
        –ü–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω dataset —Å –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏ –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è
        
        Args:
            dataset_name: –ò–º–µ –Ω–∞ –ø—Ä–æ—É—á–≤–∞–Ω–µ—Ç–æ
            n_measurements: –ë—Ä–æ–π –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è (–≤–∫–ª—é—á–∏—Ç–µ–ª–Ω–æ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏)
            
        Returns:
            –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ —Å –ø—Ä–∞–≤–∏–ª–Ω–∏—è —Ä–∞–∑–º–µ—Ä
        """
        
        # –û–ø–∏—Ç –∑–∞ –ø–æ–ª—É—á–∞–≤–∞–Ω–µ –Ω–∞ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞—â–∞ –º–∞—Ç—Ä–∏—Ü–∞
        if dataset_name in self.covariance_matrices:
            base_cov = self.covariance_matrices[dataset_name]['covariance']
            
            # –ê–∫–æ —Ä–∞–∑–º–µ—Ä—ä—Ç —Å—ä–≤–ø–∞–¥–∞, –≤—ä—Ä–Ω–∏ –¥–∏—Ä–µ–∫—Ç–Ω–æ
            if base_cov.shape[0] == n_measurements:
                return base_cov
            
            # –ê–∫–æ –∏–º–∞–º–µ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏ –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è (DA/rs, DH/rs, DV/rs)
            if n_measurements > base_cov.shape[0]:
                # –†–∞–∑—à–∏—Ä—è–≤–∞–Ω–µ –Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞—Ç–∞ –∑–∞ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏ –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è
                expanded_cov = np.zeros((n_measurements, n_measurements))
                
                # –û—Å–Ω–æ–≤–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ DV/rs
                n_basic = base_cov.shape[0]
                expanded_cov[:n_basic, :n_basic] = base_cov
                
                # –î–æ–±–∞–≤—è–Ω–µ –Ω–∞ –±–ª–æ–∫–æ–≤–µ –∑–∞ DA/rs –∏ DH/rs
                if n_measurements >= 2 * n_basic:
                    # DA/rs –±–ª–æ–∫ (–ø–æ-–º–∞–ª–∫–∏ –≥—Ä–µ—à–∫–∏)
                    da_scaling = 0.8
                    expanded_cov[n_basic:2*n_basic, n_basic:2*n_basic] = base_cov * da_scaling**2
                    
                    if n_measurements >= 3 * n_basic:
                        # DH/rs –±–ª–æ–∫ (–ø–æ-–≥–æ–ª–µ–º–∏ –≥—Ä–µ—à–∫–∏)
                        dh_scaling = 1.2
                        expanded_cov[2*n_basic:3*n_basic, 2*n_basic:3*n_basic] = base_cov * dh_scaling**2
                        
                        # –ö—Ä—ä—Å—Ç–æ—Å–∞–Ω–∏ –∫–æ—Ä–µ–ª–∞—Ü–∏–∏
                        cross_corr = -0.3  # –ê–Ω—Ç–∏-–∫–æ—Ä–µ–ª–∞—Ü–∏—è –º–µ–∂–¥—É DA/rs –∏ DH/rs
                        
                        # DA/rs - DH/rs –∫–æ—Ä–µ–ª–∞—Ü–∏—è
                        expanded_cov[n_basic:2*n_basic, 2*n_basic:3*n_basic] = base_cov * cross_corr * da_scaling * dh_scaling
                        expanded_cov[2*n_basic:3*n_basic, n_basic:2*n_basic] = base_cov * cross_corr * da_scaling * dh_scaling
                        
                        # DV/rs - DA/rs –∫–æ—Ä–µ–ª–∞—Ü–∏—è
                        expanded_cov[:n_basic, n_basic:2*n_basic] = base_cov * 0.5
                        expanded_cov[n_basic:2*n_basic, :n_basic] = base_cov * 0.5
                        
                        # DV/rs - DH/rs –∫–æ—Ä–µ–ª–∞—Ü–∏—è
                        expanded_cov[:n_basic, 2*n_basic:3*n_basic] = base_cov * 0.4
                        expanded_cov[2*n_basic:3*n_basic, :n_basic] = base_cov * 0.4
                
                return expanded_cov
        
        # Fallback: –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
        logger.warning(f"–ò–∑–ø–æ–ª–∑–≤–∞–Ω–µ –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ –∑–∞ {dataset_name} —Å {n_measurements} –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è")
        
        # –û—Å–Ω–æ–≤–Ω–∏ –≥—Ä–µ—à–∫–∏ (–ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª–Ω–æ)
        base_errors = np.array([0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2])
        
        # –†–∞–∑—à–∏—Ä—è–≤–∞–Ω–µ –∞–∫–æ –µ –Ω—É–∂–Ω–æ
        if n_measurements > len(base_errors):
            base_errors = np.tile(base_errors, (n_measurements // len(base_errors)) + 1)
        
        errors = base_errors[:n_measurements]
        
        # –ê–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–æ –º–∞—â–∞–±–∏—Ä–∞–Ω–µ
        if n_measurements > 10:  # –ê–∫–æ –∏–º–∞ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∏ –∏–∑–º–µ—Ä–≤–∞–Ω–∏—è
            n_basic = n_measurements // 3
            
            # DV/rs –≥—Ä–µ—à–∫–∏
            errors[:n_basic] = errors[:n_basic] * 1.0
            
            # DA/rs –≥—Ä–µ—à–∫–∏ (–ø–æ-—Ç–æ—á–Ω–∏)
            if n_measurements >= 2 * n_basic:
                errors[n_basic:2*n_basic] = errors[n_basic:2*n_basic] * 0.8
            
            # DH/rs –≥—Ä–µ—à–∫–∏ (–ø–æ-–Ω–µ—Ç–æ—á–Ω–∏)
            if n_measurements >= 3 * n_basic:
                errors[2*n_basic:3*n_basic] = errors[2*n_basic:3*n_basic] * 1.2
        
        return np.diag(errors**2)


def test_bao_covariance_matrices():
    """–¢–µ—Å—Ç –Ω–∞ BAO –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∏—Ç–µ –º–∞—Ç—Ä–∏—Ü–∏"""
    
    print("üß™ –¢–ï–°–¢ –ù–ê BAO –ö–û–í–ê–†–ò–ê–¶–ò–û–ù–ù–ò –ú–ê–¢–†–ò–¶–ò")
    print("=" * 60)
    
    # –°—ä–∑–¥–∞–≤–∞–Ω–µ –Ω–∞ –º–∞—Ç—Ä–∏—Ü–∏
    bao_cov = BAOCovarianceMatrices()
    
    # –†–µ–∑—é–º–µ
    bao_cov.summary()
    
    # –¢–µ—Å—Ç –Ω–∞ œá¬≤ –∏–∑—á–∏—Å–ª–µ–Ω–∏–µ
    print("\nüîç –¢–ï–°–¢ –ù–ê œá¬≤ –ò–ó–ß–ò–°–õ–ï–ù–ò–ï:")
    print("-" * 40)
    
    # –°–∏–º—É–ª–∏—Ä–∞–Ω–∏ –¥–∞–Ω–Ω–∏
    z_test = np.array([0.380, 0.510, 0.610])
    observed = np.array([15.12, 19.75, 21.40])
    predicted = np.array([14.8, 19.2, 20.9])
    
    # –î–∏–∞–≥–æ–Ω–∞–ª–µ–Ω œá¬≤
    errors = np.array([0.787, 0.902, 1.226])
    chi2_diag = np.sum(((observed - predicted) / errors)**2)
    
    # –ü—ä–ª–µ–Ω –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–µ–Ω œá¬≤
    chi2_full = bao_cov.compute_chi_squared('BOSS_DR12', observed, predicted)
    
    print(f"–î–∏–∞–≥–æ–Ω–∞–ª–µ–Ω œá¬≤: {chi2_diag:.2f}")
    print(f"–ü—ä–ª–µ–Ω œá¬≤: {chi2_full:.2f}")
    print(f"–†–∞–∑–ª–∏–∫–∞: {chi2_full - chi2_diag:.2f}")
    print(f"–ù–∞–º–∞–ª–µ–Ω–∏–µ: {(1 - chi2_full/chi2_diag)*100:.1f}%")
    
    # –¢–µ—Å—Ç –Ω–∞ –∞–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞
    print("\nüéØ –¢–ï–°–¢ –ù–ê –ê–ù–ò–ó–û–¢–†–û–ü–ù–ê –ú–ê–¢–†–ò–¶–ê:")
    print("-" * 40)
    
    aniso_data = bao_cov.generate_anisotropic_covariance('BOSS_DR12')
    print(f"–ê–Ω–∏–∑–æ—Ç—Ä–æ–ø–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞: {aniso_data['covariance'].shape}")
    print(f"DA/rs –≥—Ä–µ—à–∫–∏: {aniso_data['da_rs_errors']}")
    print(f"DH/rs –≥—Ä–µ—à–∫–∏: {aniso_data['dh_rs_errors']}")
    
    print("\n‚úÖ –¢–µ—Å—Ç—ä—Ç –∑–∞–≤—ä—Ä—à–∏ —É—Å–ø–µ—à–Ω–æ!")
    return bao_cov


if __name__ == "__main__":
    test_bao_covariance_matrices() 